"""
System information module for detecting hardware and OS constraints.
"""

import multiprocessing
import os
import platform
import subprocess
import sys
import threading
import time
from typing import Optional, Tuple

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False

# Global cache for physical core count detection
_CACHED_PHYSICAL_CORES: Optional[int] = None
_physical_cores_lock = threading.Lock()

# Global cache for spawn cost measurement
_CACHED_SPAWN_COST: Optional[float] = None
_spawn_cost_lock = threading.Lock()

# Global cache for chunking overhead measurement
_CACHED_CHUNKING_OVERHEAD: Optional[float] = None
_chunking_overhead_lock = threading.Lock()

# Global cache for available memory detection (with TTL)
_CACHED_AVAILABLE_MEMORY: Optional[int] = None
_memory_cache_timestamp: Optional[float] = None
_memory_cache_lock = threading.Lock()
# Memory cache TTL in seconds - balances performance vs accuracy
# 1 second is reasonable since memory doesn't change frequently
MEMORY_CACHE_TTL = 1.0

# Global cache for logical core count detection
_CACHED_LOGICAL_CORES: Optional[int] = None
_logical_cores_lock = threading.Lock()

# Global cache for multiprocessing start method detection
# Start method doesn't change during program execution, so no TTL needed
_CACHED_START_METHOD: Optional[str] = None
_start_method_lock = threading.Lock()

# Minimum reasonable marginal cost threshold (1ms)
# Below this, we assume measurement noise and fall back to single-worker measurement
MIN_REASONABLE_MARGINAL_COST = 0.001

# Spawn cost constants (in seconds) for different start methods
SPAWN_COST_FORK = 0.015        # fork with Copy-on-Write (~15ms)
SPAWN_COST_SPAWN = 0.2         # full interpreter initialization (~200ms)
SPAWN_COST_FORKSERVER = 0.075  # server process + fork (~75ms)

# Default chunking overhead estimate (in seconds per chunk)
# This is used as a fallback when measurement fails
DEFAULT_CHUNKING_OVERHEAD = 0.0005  # 0.5ms per chunk
from inspect import signature as _mutmut_signature
from typing import Annotated
from typing import Callable
from typing import ClassVar


MutantDict = Annotated[dict[str, Callable], "Mutant"]


def _mutmut_trampoline(orig, mutants, call_args, call_kwargs, self_arg = None):
    """Forward call to original or mutated function, depending on the environment"""
    import os
    mutant_under_test = os.environ['MUTANT_UNDER_TEST']
    if mutant_under_test == 'fail':
        from mutmut.__main__ import MutmutProgrammaticFailException
        raise MutmutProgrammaticFailException('Failed programmatically')      
    elif mutant_under_test == 'stats':
        from mutmut.__main__ import record_trampoline_hit
        record_trampoline_hit(orig.__module__ + '.' + orig.__name__)
        result = orig(*call_args, **call_kwargs)
        return result
    prefix = orig.__module__ + '.' + orig.__name__ + '__mutmut_'
    if not mutant_under_test.startswith(prefix):
        result = orig(*call_args, **call_kwargs)
        return result
    mutant_name = mutant_under_test.rpartition('.')[-1]
    if self_arg is not None:
        # call to a class method where self is not bound
        result = mutants[mutant_name](self_arg, *call_args, **call_kwargs)
    else:
        result = mutants[mutant_name](*call_args, **call_kwargs)
    return result


def x__clear_physical_cores_cache__mutmut_orig():
    """
    Clear the cached physical core count.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_PHYSICAL_CORES
    with _physical_cores_lock:
        _CACHED_PHYSICAL_CORES = None


def x__clear_physical_cores_cache__mutmut_1():
    """
    Clear the cached physical core count.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_PHYSICAL_CORES
    with _physical_cores_lock:
        _CACHED_PHYSICAL_CORES = ""

x__clear_physical_cores_cache__mutmut_mutants : ClassVar[MutantDict] = {
'x__clear_physical_cores_cache__mutmut_1': x__clear_physical_cores_cache__mutmut_1
}

def _clear_physical_cores_cache(*args, **kwargs):
    result = _mutmut_trampoline(x__clear_physical_cores_cache__mutmut_orig, x__clear_physical_cores_cache__mutmut_mutants, args, kwargs)
    return result 

_clear_physical_cores_cache.__signature__ = _mutmut_signature(x__clear_physical_cores_cache__mutmut_orig)
x__clear_physical_cores_cache__mutmut_orig.__name__ = 'x__clear_physical_cores_cache'


def x__clear_spawn_cost_cache__mutmut_orig():
    """
    Clear the cached spawn cost measurement.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_SPAWN_COST
    with _spawn_cost_lock:
        _CACHED_SPAWN_COST = None


def x__clear_spawn_cost_cache__mutmut_1():
    """
    Clear the cached spawn cost measurement.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_SPAWN_COST
    with _spawn_cost_lock:
        _CACHED_SPAWN_COST = ""

x__clear_spawn_cost_cache__mutmut_mutants : ClassVar[MutantDict] = {
'x__clear_spawn_cost_cache__mutmut_1': x__clear_spawn_cost_cache__mutmut_1
}

def _clear_spawn_cost_cache(*args, **kwargs):
    result = _mutmut_trampoline(x__clear_spawn_cost_cache__mutmut_orig, x__clear_spawn_cost_cache__mutmut_mutants, args, kwargs)
    return result 

_clear_spawn_cost_cache.__signature__ = _mutmut_signature(x__clear_spawn_cost_cache__mutmut_orig)
x__clear_spawn_cost_cache__mutmut_orig.__name__ = 'x__clear_spawn_cost_cache'


def x__clear_chunking_overhead_cache__mutmut_orig():
    """
    Clear the cached chunking overhead measurement.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_CHUNKING_OVERHEAD
    with _chunking_overhead_lock:
        _CACHED_CHUNKING_OVERHEAD = None


def x__clear_chunking_overhead_cache__mutmut_1():
    """
    Clear the cached chunking overhead measurement.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_CHUNKING_OVERHEAD
    with _chunking_overhead_lock:
        _CACHED_CHUNKING_OVERHEAD = ""

x__clear_chunking_overhead_cache__mutmut_mutants : ClassVar[MutantDict] = {
'x__clear_chunking_overhead_cache__mutmut_1': x__clear_chunking_overhead_cache__mutmut_1
}

def _clear_chunking_overhead_cache(*args, **kwargs):
    result = _mutmut_trampoline(x__clear_chunking_overhead_cache__mutmut_orig, x__clear_chunking_overhead_cache__mutmut_mutants, args, kwargs)
    return result 

_clear_chunking_overhead_cache.__signature__ = _mutmut_signature(x__clear_chunking_overhead_cache__mutmut_orig)
x__clear_chunking_overhead_cache__mutmut_orig.__name__ = 'x__clear_chunking_overhead_cache'


def x__clear_memory_cache__mutmut_orig():
    """
    Clear the cached available memory value.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp
    with _memory_cache_lock:
        _CACHED_AVAILABLE_MEMORY = None
        _memory_cache_timestamp = None


def x__clear_memory_cache__mutmut_1():
    """
    Clear the cached available memory value.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp
    with _memory_cache_lock:
        _CACHED_AVAILABLE_MEMORY = ""
        _memory_cache_timestamp = None


def x__clear_memory_cache__mutmut_2():
    """
    Clear the cached available memory value.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp
    with _memory_cache_lock:
        _CACHED_AVAILABLE_MEMORY = None
        _memory_cache_timestamp = ""

x__clear_memory_cache__mutmut_mutants : ClassVar[MutantDict] = {
'x__clear_memory_cache__mutmut_1': x__clear_memory_cache__mutmut_1, 
    'x__clear_memory_cache__mutmut_2': x__clear_memory_cache__mutmut_2
}

def _clear_memory_cache(*args, **kwargs):
    result = _mutmut_trampoline(x__clear_memory_cache__mutmut_orig, x__clear_memory_cache__mutmut_mutants, args, kwargs)
    return result 

_clear_memory_cache.__signature__ = _mutmut_signature(x__clear_memory_cache__mutmut_orig)
x__clear_memory_cache__mutmut_orig.__name__ = 'x__clear_memory_cache'


def x__clear_logical_cores_cache__mutmut_orig():
    """
    Clear the cached logical core count.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_LOGICAL_CORES
    with _logical_cores_lock:
        _CACHED_LOGICAL_CORES = None


def x__clear_logical_cores_cache__mutmut_1():
    """
    Clear the cached logical core count.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_LOGICAL_CORES
    with _logical_cores_lock:
        _CACHED_LOGICAL_CORES = ""

x__clear_logical_cores_cache__mutmut_mutants : ClassVar[MutantDict] = {
'x__clear_logical_cores_cache__mutmut_1': x__clear_logical_cores_cache__mutmut_1
}

def _clear_logical_cores_cache(*args, **kwargs):
    result = _mutmut_trampoline(x__clear_logical_cores_cache__mutmut_orig, x__clear_logical_cores_cache__mutmut_mutants, args, kwargs)
    return result 

_clear_logical_cores_cache.__signature__ = _mutmut_signature(x__clear_logical_cores_cache__mutmut_orig)
x__clear_logical_cores_cache__mutmut_orig.__name__ = 'x__clear_logical_cores_cache'


def x__clear_start_method_cache__mutmut_orig():
    """
    Clear the cached multiprocessing start method.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_START_METHOD
    with _start_method_lock:
        _CACHED_START_METHOD = None


def x__clear_start_method_cache__mutmut_1():
    """
    Clear the cached multiprocessing start method.

    This is primarily for testing purposes to ensure tests don't
    interfere with each other's cached values.

    Thread-safe: Uses lock to prevent race conditions.
    """
    global _CACHED_START_METHOD
    with _start_method_lock:
        _CACHED_START_METHOD = ""

x__clear_start_method_cache__mutmut_mutants : ClassVar[MutantDict] = {
'x__clear_start_method_cache__mutmut_1': x__clear_start_method_cache__mutmut_1
}

def _clear_start_method_cache(*args, **kwargs):
    result = _mutmut_trampoline(x__clear_start_method_cache__mutmut_orig, x__clear_start_method_cache__mutmut_mutants, args, kwargs)
    return result 

_clear_start_method_cache.__signature__ = _mutmut_signature(x__clear_start_method_cache__mutmut_orig)
x__clear_start_method_cache__mutmut_orig.__name__ = 'x__clear_start_method_cache'


def x__parse_proc_cpuinfo__mutmut_orig() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_1() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_2() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists(None):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_3() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('XX/proc/cpuinfoXX'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_4() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/PROC/CPUINFO'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_5() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = None
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_6() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = ""
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_7() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = ""

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_8() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open(None, 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_9() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', None) as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_10() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_11() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', ) as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_12() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('XX/proc/cpuinfoXX', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_13() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/PROC/CPUINFO', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_14() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'XXrXX') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_15() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'R') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_16() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = None

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_17() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith(None):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_18() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('XXprocessorXX'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_19() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('PROCESSOR'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_20() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None or current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_21() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_22() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_23() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add(None)
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_24() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = ""
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_25() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = ""
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_26() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith(None):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_27() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('XXphysical idXX'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_28() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('PHYSICAL ID'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_29() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = None
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_30() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(None)[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_31() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split('XX:XX')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_32() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[2].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_33() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith(None):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_34() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('XXcore idXX'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_35() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('CORE ID'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_36() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = None

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_37() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(None)[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_38() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split('XX:XX')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_39() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[2].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_40() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None or current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_41() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is None and current_core_id is not None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_42() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is None:
                cores.add((current_physical_id, current_core_id))

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None


def x__parse_proc_cpuinfo__mutmut_43() -> Optional[int]:
    """
    Parse /proc/cpuinfo to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if parsing fails

    Algorithm:
        Counts unique (physical_id, core_id) pairs in /proc/cpuinfo.
        This gives the actual number of physical cores, excluding hyperthreading.
    """
    try:
        if not os.path.exists('/proc/cpuinfo'):
            return None

        cores = set()
        current_physical_id = None
        current_core_id = None

        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                line = line.strip()

                # Reset IDs when starting a new processor entry
                if line.startswith('processor'):
                    # Save the previous processor's core info if we have both IDs
                    if current_physical_id is not None and current_core_id is not None:
                        cores.add((current_physical_id, current_core_id))
                    # Reset for new processor entry
                    current_physical_id = None
                    current_core_id = None
                elif line.startswith('physical id'):
                    current_physical_id = line.split(':')[1].strip()
                elif line.startswith('core id'):
                    current_core_id = line.split(':')[1].strip()

            # Don't forget the last processor entry
            if current_physical_id is not None and current_core_id is not None:
                cores.add(None)

        if cores:
            return len(cores)

        return None
    except (IOError, ValueError, IndexError):
        return None

x__parse_proc_cpuinfo__mutmut_mutants : ClassVar[MutantDict] = {
'x__parse_proc_cpuinfo__mutmut_1': x__parse_proc_cpuinfo__mutmut_1, 
    'x__parse_proc_cpuinfo__mutmut_2': x__parse_proc_cpuinfo__mutmut_2, 
    'x__parse_proc_cpuinfo__mutmut_3': x__parse_proc_cpuinfo__mutmut_3, 
    'x__parse_proc_cpuinfo__mutmut_4': x__parse_proc_cpuinfo__mutmut_4, 
    'x__parse_proc_cpuinfo__mutmut_5': x__parse_proc_cpuinfo__mutmut_5, 
    'x__parse_proc_cpuinfo__mutmut_6': x__parse_proc_cpuinfo__mutmut_6, 
    'x__parse_proc_cpuinfo__mutmut_7': x__parse_proc_cpuinfo__mutmut_7, 
    'x__parse_proc_cpuinfo__mutmut_8': x__parse_proc_cpuinfo__mutmut_8, 
    'x__parse_proc_cpuinfo__mutmut_9': x__parse_proc_cpuinfo__mutmut_9, 
    'x__parse_proc_cpuinfo__mutmut_10': x__parse_proc_cpuinfo__mutmut_10, 
    'x__parse_proc_cpuinfo__mutmut_11': x__parse_proc_cpuinfo__mutmut_11, 
    'x__parse_proc_cpuinfo__mutmut_12': x__parse_proc_cpuinfo__mutmut_12, 
    'x__parse_proc_cpuinfo__mutmut_13': x__parse_proc_cpuinfo__mutmut_13, 
    'x__parse_proc_cpuinfo__mutmut_14': x__parse_proc_cpuinfo__mutmut_14, 
    'x__parse_proc_cpuinfo__mutmut_15': x__parse_proc_cpuinfo__mutmut_15, 
    'x__parse_proc_cpuinfo__mutmut_16': x__parse_proc_cpuinfo__mutmut_16, 
    'x__parse_proc_cpuinfo__mutmut_17': x__parse_proc_cpuinfo__mutmut_17, 
    'x__parse_proc_cpuinfo__mutmut_18': x__parse_proc_cpuinfo__mutmut_18, 
    'x__parse_proc_cpuinfo__mutmut_19': x__parse_proc_cpuinfo__mutmut_19, 
    'x__parse_proc_cpuinfo__mutmut_20': x__parse_proc_cpuinfo__mutmut_20, 
    'x__parse_proc_cpuinfo__mutmut_21': x__parse_proc_cpuinfo__mutmut_21, 
    'x__parse_proc_cpuinfo__mutmut_22': x__parse_proc_cpuinfo__mutmut_22, 
    'x__parse_proc_cpuinfo__mutmut_23': x__parse_proc_cpuinfo__mutmut_23, 
    'x__parse_proc_cpuinfo__mutmut_24': x__parse_proc_cpuinfo__mutmut_24, 
    'x__parse_proc_cpuinfo__mutmut_25': x__parse_proc_cpuinfo__mutmut_25, 
    'x__parse_proc_cpuinfo__mutmut_26': x__parse_proc_cpuinfo__mutmut_26, 
    'x__parse_proc_cpuinfo__mutmut_27': x__parse_proc_cpuinfo__mutmut_27, 
    'x__parse_proc_cpuinfo__mutmut_28': x__parse_proc_cpuinfo__mutmut_28, 
    'x__parse_proc_cpuinfo__mutmut_29': x__parse_proc_cpuinfo__mutmut_29, 
    'x__parse_proc_cpuinfo__mutmut_30': x__parse_proc_cpuinfo__mutmut_30, 
    'x__parse_proc_cpuinfo__mutmut_31': x__parse_proc_cpuinfo__mutmut_31, 
    'x__parse_proc_cpuinfo__mutmut_32': x__parse_proc_cpuinfo__mutmut_32, 
    'x__parse_proc_cpuinfo__mutmut_33': x__parse_proc_cpuinfo__mutmut_33, 
    'x__parse_proc_cpuinfo__mutmut_34': x__parse_proc_cpuinfo__mutmut_34, 
    'x__parse_proc_cpuinfo__mutmut_35': x__parse_proc_cpuinfo__mutmut_35, 
    'x__parse_proc_cpuinfo__mutmut_36': x__parse_proc_cpuinfo__mutmut_36, 
    'x__parse_proc_cpuinfo__mutmut_37': x__parse_proc_cpuinfo__mutmut_37, 
    'x__parse_proc_cpuinfo__mutmut_38': x__parse_proc_cpuinfo__mutmut_38, 
    'x__parse_proc_cpuinfo__mutmut_39': x__parse_proc_cpuinfo__mutmut_39, 
    'x__parse_proc_cpuinfo__mutmut_40': x__parse_proc_cpuinfo__mutmut_40, 
    'x__parse_proc_cpuinfo__mutmut_41': x__parse_proc_cpuinfo__mutmut_41, 
    'x__parse_proc_cpuinfo__mutmut_42': x__parse_proc_cpuinfo__mutmut_42, 
    'x__parse_proc_cpuinfo__mutmut_43': x__parse_proc_cpuinfo__mutmut_43
}

def _parse_proc_cpuinfo(*args, **kwargs):
    result = _mutmut_trampoline(x__parse_proc_cpuinfo__mutmut_orig, x__parse_proc_cpuinfo__mutmut_mutants, args, kwargs)
    return result 

_parse_proc_cpuinfo.__signature__ = _mutmut_signature(x__parse_proc_cpuinfo__mutmut_orig)
x__parse_proc_cpuinfo__mutmut_orig.__name__ = 'x__parse_proc_cpuinfo'


def x__parse_lscpu__mutmut_orig() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_1() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = None

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_2() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            None,
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_3() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=None,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_4() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=None,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_5() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=None
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_6() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_7() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_8() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_9() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_10() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['XXlscpuXX', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_11() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['LSCPU', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_12() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', 'XX-p=Core,SocketXX'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_13() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=core,socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_14() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-P=CORE,SOCKET'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_15() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=False,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_16() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=False,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_17() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=2.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_18() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode == 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_19() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 1:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_20() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = None
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_21() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split(None):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_22() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('XX\nXX'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_23() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') and not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_24() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith(None) or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_25() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('XX#XX') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_26() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_27() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                break

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_28() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = None
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_29() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(None)
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_30() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split('XX,XX')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_31() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) > 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_32() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 3:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_33() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = None
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_34() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[1].strip()
                socket_id = parts[1].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_35() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = None
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_36() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[2].strip()
                cores.add((socket_id, core_id))

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None


def x__parse_lscpu__mutmut_37() -> Optional[int]:
    """
    Use lscpu command to determine physical core count on Linux.

    Returns:
        Number of physical cores, or None if command fails

    Note:
        This is a secondary fallback after /proc/cpuinfo parsing.
        lscpu is part of util-linux and should be available on most Linux systems.
    """
    try:
        # Run lscpu and capture output
        result = subprocess.run(
            ['lscpu', '-p=Core,Socket'],
            capture_output=True,
            text=True,
            timeout=1.0
        )

        if result.returncode != 0:
            return None

        # Parse the output to count unique (socket, core) pairs
        cores = set()
        for line in result.stdout.split('\n'):
            # Skip comments and empty lines
            if line.startswith('#') or not line.strip():
                continue

            parts = line.split(',')
            if len(parts) >= 2:
                core_id = parts[0].strip()
                socket_id = parts[1].strip()
                cores.add(None)

        if cores:
            return len(cores)

        return None
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired, ValueError):
        return None

x__parse_lscpu__mutmut_mutants : ClassVar[MutantDict] = {
'x__parse_lscpu__mutmut_1': x__parse_lscpu__mutmut_1, 
    'x__parse_lscpu__mutmut_2': x__parse_lscpu__mutmut_2, 
    'x__parse_lscpu__mutmut_3': x__parse_lscpu__mutmut_3, 
    'x__parse_lscpu__mutmut_4': x__parse_lscpu__mutmut_4, 
    'x__parse_lscpu__mutmut_5': x__parse_lscpu__mutmut_5, 
    'x__parse_lscpu__mutmut_6': x__parse_lscpu__mutmut_6, 
    'x__parse_lscpu__mutmut_7': x__parse_lscpu__mutmut_7, 
    'x__parse_lscpu__mutmut_8': x__parse_lscpu__mutmut_8, 
    'x__parse_lscpu__mutmut_9': x__parse_lscpu__mutmut_9, 
    'x__parse_lscpu__mutmut_10': x__parse_lscpu__mutmut_10, 
    'x__parse_lscpu__mutmut_11': x__parse_lscpu__mutmut_11, 
    'x__parse_lscpu__mutmut_12': x__parse_lscpu__mutmut_12, 
    'x__parse_lscpu__mutmut_13': x__parse_lscpu__mutmut_13, 
    'x__parse_lscpu__mutmut_14': x__parse_lscpu__mutmut_14, 
    'x__parse_lscpu__mutmut_15': x__parse_lscpu__mutmut_15, 
    'x__parse_lscpu__mutmut_16': x__parse_lscpu__mutmut_16, 
    'x__parse_lscpu__mutmut_17': x__parse_lscpu__mutmut_17, 
    'x__parse_lscpu__mutmut_18': x__parse_lscpu__mutmut_18, 
    'x__parse_lscpu__mutmut_19': x__parse_lscpu__mutmut_19, 
    'x__parse_lscpu__mutmut_20': x__parse_lscpu__mutmut_20, 
    'x__parse_lscpu__mutmut_21': x__parse_lscpu__mutmut_21, 
    'x__parse_lscpu__mutmut_22': x__parse_lscpu__mutmut_22, 
    'x__parse_lscpu__mutmut_23': x__parse_lscpu__mutmut_23, 
    'x__parse_lscpu__mutmut_24': x__parse_lscpu__mutmut_24, 
    'x__parse_lscpu__mutmut_25': x__parse_lscpu__mutmut_25, 
    'x__parse_lscpu__mutmut_26': x__parse_lscpu__mutmut_26, 
    'x__parse_lscpu__mutmut_27': x__parse_lscpu__mutmut_27, 
    'x__parse_lscpu__mutmut_28': x__parse_lscpu__mutmut_28, 
    'x__parse_lscpu__mutmut_29': x__parse_lscpu__mutmut_29, 
    'x__parse_lscpu__mutmut_30': x__parse_lscpu__mutmut_30, 
    'x__parse_lscpu__mutmut_31': x__parse_lscpu__mutmut_31, 
    'x__parse_lscpu__mutmut_32': x__parse_lscpu__mutmut_32, 
    'x__parse_lscpu__mutmut_33': x__parse_lscpu__mutmut_33, 
    'x__parse_lscpu__mutmut_34': x__parse_lscpu__mutmut_34, 
    'x__parse_lscpu__mutmut_35': x__parse_lscpu__mutmut_35, 
    'x__parse_lscpu__mutmut_36': x__parse_lscpu__mutmut_36, 
    'x__parse_lscpu__mutmut_37': x__parse_lscpu__mutmut_37
}

def _parse_lscpu(*args, **kwargs):
    result = _mutmut_trampoline(x__parse_lscpu__mutmut_orig, x__parse_lscpu__mutmut_mutants, args, kwargs)
    return result 

_parse_lscpu.__signature__ = _mutmut_signature(x__parse_lscpu__mutmut_orig)
x__parse_lscpu__mutmut_orig.__name__ = 'x__parse_lscpu'


def x_get_physical_cores__mutmut_orig() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_1() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_2() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_3() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = ""

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_4() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = None
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_5() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=None)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_6() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=True)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_7() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_8() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = None

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_9() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None or platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_10() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is not None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_11() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() != "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_12() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "XXLinuxXX":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_13() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_14() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "LINUX":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_15() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = None
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_16() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_17() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = None
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_18() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = None
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_19() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_20() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = None

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_21() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is not None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_22() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = None
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_23() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical >= 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_24() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 2:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_25() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = None
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_26() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(None, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_27() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, None)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_28() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_29() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, )
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_30() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(2, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_31() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical / 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_32() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 3)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_33() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = None

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_34() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is not None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_35() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = None

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_36() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 2

        # Cache the result
        _CACHED_PHYSICAL_CORES = physical_cores
        return physical_cores


def x_get_physical_cores__mutmut_37() -> int:
    """
    Get the number of physical CPU cores.

    The physical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of physical cores, using the best available detection method

    Detection Strategy (in order of preference):
        1. psutil (most reliable, cross-platform)
        2. /proc/cpuinfo parsing (Linux, no dependencies)
        3. lscpu command (Linux, secondary fallback)
        4. Logical cores / 2 (conservative estimate for hyperthreading)
        5. 1 core (absolute fallback)

    Rationale:
        For CPU-bound tasks, using logical cores (with hyperthreading) can lead
        to over-subscription and worse performance. Physical cores provide better
        parallelization characteristics.

    Performance:
        Cached globally after first call to eliminate redundant system calls,
        file I/O, and subprocess spawns on subsequent calls. This is especially
        beneficial when multiple optimizations occur in the same program.
    """
    global _CACHED_PHYSICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_PHYSICAL_CORES is not None:
        return _CACHED_PHYSICAL_CORES

    # Acquire lock for detection
    with _physical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_PHYSICAL_CORES is not None:
            return _CACHED_PHYSICAL_CORES

        # Perform detection (only one thread reaches here)
        physical_cores = None

        # Strategy 1: Use psutil if available (best method)
        if HAS_PSUTIL:
            # psutil can distinguish between physical and logical cores
            physical = psutil.cpu_count(logical=False)
            if physical is not None:
                physical_cores = physical

        # Strategy 2: Try /proc/cpuinfo on Linux (no dependencies)
        if physical_cores is None and platform.system() == "Linux":
            physical = _parse_proc_cpuinfo()
            if physical is not None:
                physical_cores = physical
            else:
                # Strategy 3: Try lscpu command on Linux (secondary fallback)
                physical = _parse_lscpu()
                if physical is not None:
                    physical_cores = physical

        # Strategy 4: Conservative estimate - assume hyperthreading (logical / 2)
        # This is better than using all logical cores for CPU-bound tasks
        # Note: This calls get_logical_cores() which uses a different lock
        # (_logical_cores_lock), so there's no deadlock risk. get_logical_cores()
        # never calls get_physical_cores(), preventing circular dependencies.
        if physical_cores is None:
            logical = get_logical_cores()
            if logical > 1:
                # Assume hyperthreading is enabled (common on modern CPUs)
                # Divide by 2 to get approximate physical core count
                physical_cores = max(1, logical // 2)
            else:
                physical_cores = logical

        # Strategy 5: Absolute fallback
        if physical_cores is None:
            physical_cores = 1

        # Cache the result
        _CACHED_PHYSICAL_CORES = None
        return physical_cores

x_get_physical_cores__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_physical_cores__mutmut_1': x_get_physical_cores__mutmut_1, 
    'x_get_physical_cores__mutmut_2': x_get_physical_cores__mutmut_2, 
    'x_get_physical_cores__mutmut_3': x_get_physical_cores__mutmut_3, 
    'x_get_physical_cores__mutmut_4': x_get_physical_cores__mutmut_4, 
    'x_get_physical_cores__mutmut_5': x_get_physical_cores__mutmut_5, 
    'x_get_physical_cores__mutmut_6': x_get_physical_cores__mutmut_6, 
    'x_get_physical_cores__mutmut_7': x_get_physical_cores__mutmut_7, 
    'x_get_physical_cores__mutmut_8': x_get_physical_cores__mutmut_8, 
    'x_get_physical_cores__mutmut_9': x_get_physical_cores__mutmut_9, 
    'x_get_physical_cores__mutmut_10': x_get_physical_cores__mutmut_10, 
    'x_get_physical_cores__mutmut_11': x_get_physical_cores__mutmut_11, 
    'x_get_physical_cores__mutmut_12': x_get_physical_cores__mutmut_12, 
    'x_get_physical_cores__mutmut_13': x_get_physical_cores__mutmut_13, 
    'x_get_physical_cores__mutmut_14': x_get_physical_cores__mutmut_14, 
    'x_get_physical_cores__mutmut_15': x_get_physical_cores__mutmut_15, 
    'x_get_physical_cores__mutmut_16': x_get_physical_cores__mutmut_16, 
    'x_get_physical_cores__mutmut_17': x_get_physical_cores__mutmut_17, 
    'x_get_physical_cores__mutmut_18': x_get_physical_cores__mutmut_18, 
    'x_get_physical_cores__mutmut_19': x_get_physical_cores__mutmut_19, 
    'x_get_physical_cores__mutmut_20': x_get_physical_cores__mutmut_20, 
    'x_get_physical_cores__mutmut_21': x_get_physical_cores__mutmut_21, 
    'x_get_physical_cores__mutmut_22': x_get_physical_cores__mutmut_22, 
    'x_get_physical_cores__mutmut_23': x_get_physical_cores__mutmut_23, 
    'x_get_physical_cores__mutmut_24': x_get_physical_cores__mutmut_24, 
    'x_get_physical_cores__mutmut_25': x_get_physical_cores__mutmut_25, 
    'x_get_physical_cores__mutmut_26': x_get_physical_cores__mutmut_26, 
    'x_get_physical_cores__mutmut_27': x_get_physical_cores__mutmut_27, 
    'x_get_physical_cores__mutmut_28': x_get_physical_cores__mutmut_28, 
    'x_get_physical_cores__mutmut_29': x_get_physical_cores__mutmut_29, 
    'x_get_physical_cores__mutmut_30': x_get_physical_cores__mutmut_30, 
    'x_get_physical_cores__mutmut_31': x_get_physical_cores__mutmut_31, 
    'x_get_physical_cores__mutmut_32': x_get_physical_cores__mutmut_32, 
    'x_get_physical_cores__mutmut_33': x_get_physical_cores__mutmut_33, 
    'x_get_physical_cores__mutmut_34': x_get_physical_cores__mutmut_34, 
    'x_get_physical_cores__mutmut_35': x_get_physical_cores__mutmut_35, 
    'x_get_physical_cores__mutmut_36': x_get_physical_cores__mutmut_36, 
    'x_get_physical_cores__mutmut_37': x_get_physical_cores__mutmut_37
}

def get_physical_cores(*args, **kwargs):
    result = _mutmut_trampoline(x_get_physical_cores__mutmut_orig, x_get_physical_cores__mutmut_mutants, args, kwargs)
    return result 

get_physical_cores.__signature__ = _mutmut_signature(x_get_physical_cores__mutmut_orig)
x_get_physical_cores__mutmut_orig.__name__ = 'x_get_physical_cores'


def x_get_logical_cores__mutmut_orig() -> int:
    """
    Get the number of logical CPU cores (including hyperthreading).

    The logical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of logical cores, or 1 if detection fails

    Rationale:
        Logical cores include hyperthreading/SMT cores. This is useful for
        diagnostic information and understanding the system topology, though
        physical cores are typically preferred for CPU-bound parallelization.

    Performance:
        Cached globally after first call to eliminate redundant system calls
        on subsequent calls. This is especially beneficial when multiple
        optimizations occur in the same program.
    """
    global _CACHED_LOGICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_LOGICAL_CORES is not None:
        return _CACHED_LOGICAL_CORES

    # Acquire lock for detection
    with _logical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_LOGICAL_CORES is not None:
            return _CACHED_LOGICAL_CORES

        # Perform detection (only one thread reaches here)
        logical_cores = os.cpu_count()

        # Fallback to 1 if detection fails
        if logical_cores is None:
            logical_cores = 1

        # Cache the result
        _CACHED_LOGICAL_CORES = logical_cores
        return logical_cores


def x_get_logical_cores__mutmut_1() -> int:
    """
    Get the number of logical CPU cores (including hyperthreading).

    The logical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of logical cores, or 1 if detection fails

    Rationale:
        Logical cores include hyperthreading/SMT cores. This is useful for
        diagnostic information and understanding the system topology, though
        physical cores are typically preferred for CPU-bound parallelization.

    Performance:
        Cached globally after first call to eliminate redundant system calls
        on subsequent calls. This is especially beneficial when multiple
        optimizations occur in the same program.
    """
    global _CACHED_LOGICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_LOGICAL_CORES is None:
        return _CACHED_LOGICAL_CORES

    # Acquire lock for detection
    with _logical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_LOGICAL_CORES is not None:
            return _CACHED_LOGICAL_CORES

        # Perform detection (only one thread reaches here)
        logical_cores = os.cpu_count()

        # Fallback to 1 if detection fails
        if logical_cores is None:
            logical_cores = 1

        # Cache the result
        _CACHED_LOGICAL_CORES = logical_cores
        return logical_cores


def x_get_logical_cores__mutmut_2() -> int:
    """
    Get the number of logical CPU cores (including hyperthreading).

    The logical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of logical cores, or 1 if detection fails

    Rationale:
        Logical cores include hyperthreading/SMT cores. This is useful for
        diagnostic information and understanding the system topology, though
        physical cores are typically preferred for CPU-bound parallelization.

    Performance:
        Cached globally after first call to eliminate redundant system calls
        on subsequent calls. This is especially beneficial when multiple
        optimizations occur in the same program.
    """
    global _CACHED_LOGICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_LOGICAL_CORES is not None:
        return _CACHED_LOGICAL_CORES

    # Acquire lock for detection
    with _logical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_LOGICAL_CORES is None:
            return _CACHED_LOGICAL_CORES

        # Perform detection (only one thread reaches here)
        logical_cores = os.cpu_count()

        # Fallback to 1 if detection fails
        if logical_cores is None:
            logical_cores = 1

        # Cache the result
        _CACHED_LOGICAL_CORES = logical_cores
        return logical_cores


def x_get_logical_cores__mutmut_3() -> int:
    """
    Get the number of logical CPU cores (including hyperthreading).

    The logical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of logical cores, or 1 if detection fails

    Rationale:
        Logical cores include hyperthreading/SMT cores. This is useful for
        diagnostic information and understanding the system topology, though
        physical cores are typically preferred for CPU-bound parallelization.

    Performance:
        Cached globally after first call to eliminate redundant system calls
        on subsequent calls. This is especially beneficial when multiple
        optimizations occur in the same program.
    """
    global _CACHED_LOGICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_LOGICAL_CORES is not None:
        return _CACHED_LOGICAL_CORES

    # Acquire lock for detection
    with _logical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_LOGICAL_CORES is not None:
            return _CACHED_LOGICAL_CORES

        # Perform detection (only one thread reaches here)
        logical_cores = None

        # Fallback to 1 if detection fails
        if logical_cores is None:
            logical_cores = 1

        # Cache the result
        _CACHED_LOGICAL_CORES = logical_cores
        return logical_cores


def x_get_logical_cores__mutmut_4() -> int:
    """
    Get the number of logical CPU cores (including hyperthreading).

    The logical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of logical cores, or 1 if detection fails

    Rationale:
        Logical cores include hyperthreading/SMT cores. This is useful for
        diagnostic information and understanding the system topology, though
        physical cores are typically preferred for CPU-bound parallelization.

    Performance:
        Cached globally after first call to eliminate redundant system calls
        on subsequent calls. This is especially beneficial when multiple
        optimizations occur in the same program.
    """
    global _CACHED_LOGICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_LOGICAL_CORES is not None:
        return _CACHED_LOGICAL_CORES

    # Acquire lock for detection
    with _logical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_LOGICAL_CORES is not None:
            return _CACHED_LOGICAL_CORES

        # Perform detection (only one thread reaches here)
        logical_cores = os.cpu_count()

        # Fallback to 1 if detection fails
        if logical_cores is not None:
            logical_cores = 1

        # Cache the result
        _CACHED_LOGICAL_CORES = logical_cores
        return logical_cores


def x_get_logical_cores__mutmut_5() -> int:
    """
    Get the number of logical CPU cores (including hyperthreading).

    The logical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of logical cores, or 1 if detection fails

    Rationale:
        Logical cores include hyperthreading/SMT cores. This is useful for
        diagnostic information and understanding the system topology, though
        physical cores are typically preferred for CPU-bound parallelization.

    Performance:
        Cached globally after first call to eliminate redundant system calls
        on subsequent calls. This is especially beneficial when multiple
        optimizations occur in the same program.
    """
    global _CACHED_LOGICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_LOGICAL_CORES is not None:
        return _CACHED_LOGICAL_CORES

    # Acquire lock for detection
    with _logical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_LOGICAL_CORES is not None:
            return _CACHED_LOGICAL_CORES

        # Perform detection (only one thread reaches here)
        logical_cores = os.cpu_count()

        # Fallback to 1 if detection fails
        if logical_cores is None:
            logical_cores = None

        # Cache the result
        _CACHED_LOGICAL_CORES = logical_cores
        return logical_cores


def x_get_logical_cores__mutmut_6() -> int:
    """
    Get the number of logical CPU cores (including hyperthreading).

    The logical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of logical cores, or 1 if detection fails

    Rationale:
        Logical cores include hyperthreading/SMT cores. This is useful for
        diagnostic information and understanding the system topology, though
        physical cores are typically preferred for CPU-bound parallelization.

    Performance:
        Cached globally after first call to eliminate redundant system calls
        on subsequent calls. This is especially beneficial when multiple
        optimizations occur in the same program.
    """
    global _CACHED_LOGICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_LOGICAL_CORES is not None:
        return _CACHED_LOGICAL_CORES

    # Acquire lock for detection
    with _logical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_LOGICAL_CORES is not None:
            return _CACHED_LOGICAL_CORES

        # Perform detection (only one thread reaches here)
        logical_cores = os.cpu_count()

        # Fallback to 1 if detection fails
        if logical_cores is None:
            logical_cores = 2

        # Cache the result
        _CACHED_LOGICAL_CORES = logical_cores
        return logical_cores


def x_get_logical_cores__mutmut_7() -> int:
    """
    Get the number of logical CPU cores (including hyperthreading).

    The logical core count is cached globally after first detection since
    it's a system constant that never changes during program execution.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Number of logical cores, or 1 if detection fails

    Rationale:
        Logical cores include hyperthreading/SMT cores. This is useful for
        diagnostic information and understanding the system topology, though
        physical cores are typically preferred for CPU-bound parallelization.

    Performance:
        Cached globally after first call to eliminate redundant system calls
        on subsequent calls. This is especially beneficial when multiple
        optimizations occur in the same program.
    """
    global _CACHED_LOGICAL_CORES

    # Quick check without lock (optimization for common case)
    if _CACHED_LOGICAL_CORES is not None:
        return _CACHED_LOGICAL_CORES

    # Acquire lock for detection
    with _logical_cores_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if _CACHED_LOGICAL_CORES is not None:
            return _CACHED_LOGICAL_CORES

        # Perform detection (only one thread reaches here)
        logical_cores = os.cpu_count()

        # Fallback to 1 if detection fails
        if logical_cores is None:
            logical_cores = 1

        # Cache the result
        _CACHED_LOGICAL_CORES = None
        return logical_cores

x_get_logical_cores__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_logical_cores__mutmut_1': x_get_logical_cores__mutmut_1, 
    'x_get_logical_cores__mutmut_2': x_get_logical_cores__mutmut_2, 
    'x_get_logical_cores__mutmut_3': x_get_logical_cores__mutmut_3, 
    'x_get_logical_cores__mutmut_4': x_get_logical_cores__mutmut_4, 
    'x_get_logical_cores__mutmut_5': x_get_logical_cores__mutmut_5, 
    'x_get_logical_cores__mutmut_6': x_get_logical_cores__mutmut_6, 
    'x_get_logical_cores__mutmut_7': x_get_logical_cores__mutmut_7
}

def get_logical_cores(*args, **kwargs):
    result = _mutmut_trampoline(x_get_logical_cores__mutmut_orig, x_get_logical_cores__mutmut_mutants, args, kwargs)
    return result 

get_logical_cores.__signature__ = _mutmut_signature(x_get_logical_cores__mutmut_orig)
x_get_logical_cores__mutmut_orig.__name__ = 'x_get_logical_cores'


def _noop_worker(_):
    """No-op worker function for benchmarking process spawn overhead."""
    pass


def x_measure_spawn_cost__mutmut_orig(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_1(timeout: float = 3.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_2(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_3(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_4(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = None

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_5(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = None
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_6(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=None) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_7(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_8(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = None
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_9(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(None, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_10(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, None)
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_11(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async((None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_12(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, )
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_13(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=None)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_14(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = None
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_15(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = None

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_16(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 + start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_17(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = None
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_18(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=None) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_19(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=3) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_20(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = None
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_21(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(None, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_22(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, None) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_23(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async((None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_24(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, ) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_25(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(None)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_26(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(3)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_27(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=None)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_28(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = None
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_29(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = None

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_30(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 + start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_31(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = None

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_32(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers + time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_33(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost >= MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_34(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = None

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_35(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = None
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_36(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method != 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_37(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'XXforkXX':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_38(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'FORK':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_39(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = None  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_40(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 1.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_41(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 1.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_42(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method != 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_43(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'XXspawnXX':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_44(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'SPAWN':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_45(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = None   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_46(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 1.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_47(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 2.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_48(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method != 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_49(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'XXforkserverXX':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_50(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'FORKSERVER':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_51(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = None   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_52(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 1.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_53(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 1.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_54(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = None

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_55(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 1.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_56(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 2.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_57(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_58(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound < per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_59(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost < max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_60(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = None
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_61(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers <= time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_62(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker / 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_63(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 2.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_64(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = None
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_65(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_66(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate * 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_67(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 11 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_68(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 < per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_69(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost < fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_70(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate / 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_71(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 11):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_72(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = None
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_73(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost >= time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_74(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers / 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_75(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 1.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_76(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = None
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_77(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = None
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_78(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST < time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_79(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker < max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_80(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(None, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_81(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, None):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_82(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_83(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, ):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_84(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(1.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_85(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate / 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_86(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 6):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_87(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = None
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_88(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = None
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = fallback_estimate
            return fallback_estimate


def x_measure_spawn_cost__mutmut_89(timeout: float = 2.0) -> float:
    """
    Measure the actual per-worker process spawn cost by benchmarking.

    This function measures the marginal cost of spawning additional workers
    by comparing pool creation times with different worker counts. This gives
    a more accurate per-worker cost than measuring a single worker pool.

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Enhanced with quality validation to ensure reliable measurements across
    diverse system conditions (similar to chunking overhead measurement).

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-worker spawn cost in seconds, or OS-based estimate on failure

    Algorithm:
        1. Measure time to create pool with 1 worker
        2. Measure time to create pool with 2 workers
        3. Calculate marginal cost: (time_2_workers - time_1_worker) / 1
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-worker cost from fixed pool initialization overhead.

    Quality Validation:
        - Check 1: Reasonable range based on start method
        - Check 2: Signal strength (2-worker measurement significantly larger)
        - Check 3: Consistency with start method expectations
        - Check 4: Overhead fraction validation

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        OS-based estimates based on the multiprocessing start method.

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_SPAWN_COST

    # Quick check without lock (optimization for common case)
    if _CACHED_SPAWN_COST is not None:
        return _CACHED_SPAWN_COST

    # Acquire lock for measurement
    with _spawn_cost_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_SPAWN_COST is not None:
            return _CACHED_SPAWN_COST

        # Perform measurement (only one thread reaches here)
        # Get fallback value early for quality checks
        fallback_estimate = get_spawn_cost_estimate()

        try:
            # Measure time to create pool with 1 worker
            start_1 = time.perf_counter()
            with multiprocessing.Pool(processes=1) as pool:
                result = pool.apply_async(_noop_worker, (None,))
                result.get(timeout=timeout)
            end_1 = time.perf_counter()
            time_1_worker = end_1 - start_1

            # Measure time to create pool with 2 workers
            start_2 = time.perf_counter()
            with multiprocessing.Pool(processes=2) as pool:
                # Submit tasks to ensure both workers are initialized
                results = [pool.apply_async(_noop_worker, (None,)) for _ in range(2)]
                for result in results:
                    result.get(timeout=timeout)
            end_2 = time.perf_counter()
            time_2_workers = end_2 - start_2

            # Calculate marginal cost per worker
            # This removes fixed pool initialization overhead
            marginal_cost = time_2_workers - time_1_worker

            # Enhanced validation: Check multiple quality criteria
            # If marginal cost is positive and reasonable, use it with validation
            if marginal_cost > MIN_REASONABLE_MARGINAL_COST:
                per_worker_cost = marginal_cost

                # Quality check 1: Reasonable range based on start method
                # fork: 1ms to 100ms, spawn: 50ms to 1000ms, forkserver: 10ms to 500ms
                start_method = get_multiprocessing_start_method()
                if start_method == 'fork':
                    min_bound, max_bound = 0.001, 0.1  # 1ms to 100ms
                elif start_method == 'spawn':
                    min_bound, max_bound = 0.05, 1.0   # 50ms to 1000ms
                elif start_method == 'forkserver':
                    min_bound, max_bound = 0.01, 0.5   # 10ms to 500ms
                else:
                    # Unknown start method - use conservative bounds
                    min_bound, max_bound = 0.001, 1.0

                if not (min_bound <= per_worker_cost <= max_bound):
                    # Outside reasonable bounds for this start method
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 2: Signal strength validation
                # 2-worker measurement should be at least 10% longer than 1-worker
                # This ensures we're measuring real spawn cost, not noise
                if time_2_workers < time_1_worker * 1.1:
                    # Signal too weak - likely measurement noise
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 3: Consistency with start method expectations
                # Measured value should be within 10x of the expected value
                # This catches measurements that are wildly off
                if not (fallback_estimate / 10 <= per_worker_cost <= fallback_estimate * 10):
                    # Measurement inconsistent with expectations
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # Quality check 4: Overhead fraction validation
                # Marginal cost should be reasonable fraction of 2-worker time
                # If marginal cost > 90% of total time, something is wrong
                if marginal_cost > time_2_workers * 0.9:
                    # Overhead seems unrealistically high relative to total
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

                # All quality checks passed - use measured value
                _CACHED_SPAWN_COST = per_worker_cost
                return per_worker_cost
            else:
                # Marginal cost too small or negative - fall back to 1-worker measurement
                # But validate it first
                if MIN_REASONABLE_MARGINAL_COST <= time_1_worker <= max(0.1, fallback_estimate * 5):
                    # 1-worker measurement seems reasonable
                    _CACHED_SPAWN_COST = time_1_worker
                    return time_1_worker
                else:
                    # Even 1-worker measurement seems unreliable
                    _CACHED_SPAWN_COST = fallback_estimate
                    return fallback_estimate

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to OS-based estimate
            # OSError: System-level issues (e.g., resource exhaustion)
            # TimeoutError: Benchmark took too long
            # ValueError: Invalid parameter values
            # ProcessError: Multiprocessing-specific failures
            _CACHED_SPAWN_COST = None
            return fallback_estimate

x_measure_spawn_cost__mutmut_mutants : ClassVar[MutantDict] = {
'x_measure_spawn_cost__mutmut_1': x_measure_spawn_cost__mutmut_1, 
    'x_measure_spawn_cost__mutmut_2': x_measure_spawn_cost__mutmut_2, 
    'x_measure_spawn_cost__mutmut_3': x_measure_spawn_cost__mutmut_3, 
    'x_measure_spawn_cost__mutmut_4': x_measure_spawn_cost__mutmut_4, 
    'x_measure_spawn_cost__mutmut_5': x_measure_spawn_cost__mutmut_5, 
    'x_measure_spawn_cost__mutmut_6': x_measure_spawn_cost__mutmut_6, 
    'x_measure_spawn_cost__mutmut_7': x_measure_spawn_cost__mutmut_7, 
    'x_measure_spawn_cost__mutmut_8': x_measure_spawn_cost__mutmut_8, 
    'x_measure_spawn_cost__mutmut_9': x_measure_spawn_cost__mutmut_9, 
    'x_measure_spawn_cost__mutmut_10': x_measure_spawn_cost__mutmut_10, 
    'x_measure_spawn_cost__mutmut_11': x_measure_spawn_cost__mutmut_11, 
    'x_measure_spawn_cost__mutmut_12': x_measure_spawn_cost__mutmut_12, 
    'x_measure_spawn_cost__mutmut_13': x_measure_spawn_cost__mutmut_13, 
    'x_measure_spawn_cost__mutmut_14': x_measure_spawn_cost__mutmut_14, 
    'x_measure_spawn_cost__mutmut_15': x_measure_spawn_cost__mutmut_15, 
    'x_measure_spawn_cost__mutmut_16': x_measure_spawn_cost__mutmut_16, 
    'x_measure_spawn_cost__mutmut_17': x_measure_spawn_cost__mutmut_17, 
    'x_measure_spawn_cost__mutmut_18': x_measure_spawn_cost__mutmut_18, 
    'x_measure_spawn_cost__mutmut_19': x_measure_spawn_cost__mutmut_19, 
    'x_measure_spawn_cost__mutmut_20': x_measure_spawn_cost__mutmut_20, 
    'x_measure_spawn_cost__mutmut_21': x_measure_spawn_cost__mutmut_21, 
    'x_measure_spawn_cost__mutmut_22': x_measure_spawn_cost__mutmut_22, 
    'x_measure_spawn_cost__mutmut_23': x_measure_spawn_cost__mutmut_23, 
    'x_measure_spawn_cost__mutmut_24': x_measure_spawn_cost__mutmut_24, 
    'x_measure_spawn_cost__mutmut_25': x_measure_spawn_cost__mutmut_25, 
    'x_measure_spawn_cost__mutmut_26': x_measure_spawn_cost__mutmut_26, 
    'x_measure_spawn_cost__mutmut_27': x_measure_spawn_cost__mutmut_27, 
    'x_measure_spawn_cost__mutmut_28': x_measure_spawn_cost__mutmut_28, 
    'x_measure_spawn_cost__mutmut_29': x_measure_spawn_cost__mutmut_29, 
    'x_measure_spawn_cost__mutmut_30': x_measure_spawn_cost__mutmut_30, 
    'x_measure_spawn_cost__mutmut_31': x_measure_spawn_cost__mutmut_31, 
    'x_measure_spawn_cost__mutmut_32': x_measure_spawn_cost__mutmut_32, 
    'x_measure_spawn_cost__mutmut_33': x_measure_spawn_cost__mutmut_33, 
    'x_measure_spawn_cost__mutmut_34': x_measure_spawn_cost__mutmut_34, 
    'x_measure_spawn_cost__mutmut_35': x_measure_spawn_cost__mutmut_35, 
    'x_measure_spawn_cost__mutmut_36': x_measure_spawn_cost__mutmut_36, 
    'x_measure_spawn_cost__mutmut_37': x_measure_spawn_cost__mutmut_37, 
    'x_measure_spawn_cost__mutmut_38': x_measure_spawn_cost__mutmut_38, 
    'x_measure_spawn_cost__mutmut_39': x_measure_spawn_cost__mutmut_39, 
    'x_measure_spawn_cost__mutmut_40': x_measure_spawn_cost__mutmut_40, 
    'x_measure_spawn_cost__mutmut_41': x_measure_spawn_cost__mutmut_41, 
    'x_measure_spawn_cost__mutmut_42': x_measure_spawn_cost__mutmut_42, 
    'x_measure_spawn_cost__mutmut_43': x_measure_spawn_cost__mutmut_43, 
    'x_measure_spawn_cost__mutmut_44': x_measure_spawn_cost__mutmut_44, 
    'x_measure_spawn_cost__mutmut_45': x_measure_spawn_cost__mutmut_45, 
    'x_measure_spawn_cost__mutmut_46': x_measure_spawn_cost__mutmut_46, 
    'x_measure_spawn_cost__mutmut_47': x_measure_spawn_cost__mutmut_47, 
    'x_measure_spawn_cost__mutmut_48': x_measure_spawn_cost__mutmut_48, 
    'x_measure_spawn_cost__mutmut_49': x_measure_spawn_cost__mutmut_49, 
    'x_measure_spawn_cost__mutmut_50': x_measure_spawn_cost__mutmut_50, 
    'x_measure_spawn_cost__mutmut_51': x_measure_spawn_cost__mutmut_51, 
    'x_measure_spawn_cost__mutmut_52': x_measure_spawn_cost__mutmut_52, 
    'x_measure_spawn_cost__mutmut_53': x_measure_spawn_cost__mutmut_53, 
    'x_measure_spawn_cost__mutmut_54': x_measure_spawn_cost__mutmut_54, 
    'x_measure_spawn_cost__mutmut_55': x_measure_spawn_cost__mutmut_55, 
    'x_measure_spawn_cost__mutmut_56': x_measure_spawn_cost__mutmut_56, 
    'x_measure_spawn_cost__mutmut_57': x_measure_spawn_cost__mutmut_57, 
    'x_measure_spawn_cost__mutmut_58': x_measure_spawn_cost__mutmut_58, 
    'x_measure_spawn_cost__mutmut_59': x_measure_spawn_cost__mutmut_59, 
    'x_measure_spawn_cost__mutmut_60': x_measure_spawn_cost__mutmut_60, 
    'x_measure_spawn_cost__mutmut_61': x_measure_spawn_cost__mutmut_61, 
    'x_measure_spawn_cost__mutmut_62': x_measure_spawn_cost__mutmut_62, 
    'x_measure_spawn_cost__mutmut_63': x_measure_spawn_cost__mutmut_63, 
    'x_measure_spawn_cost__mutmut_64': x_measure_spawn_cost__mutmut_64, 
    'x_measure_spawn_cost__mutmut_65': x_measure_spawn_cost__mutmut_65, 
    'x_measure_spawn_cost__mutmut_66': x_measure_spawn_cost__mutmut_66, 
    'x_measure_spawn_cost__mutmut_67': x_measure_spawn_cost__mutmut_67, 
    'x_measure_spawn_cost__mutmut_68': x_measure_spawn_cost__mutmut_68, 
    'x_measure_spawn_cost__mutmut_69': x_measure_spawn_cost__mutmut_69, 
    'x_measure_spawn_cost__mutmut_70': x_measure_spawn_cost__mutmut_70, 
    'x_measure_spawn_cost__mutmut_71': x_measure_spawn_cost__mutmut_71, 
    'x_measure_spawn_cost__mutmut_72': x_measure_spawn_cost__mutmut_72, 
    'x_measure_spawn_cost__mutmut_73': x_measure_spawn_cost__mutmut_73, 
    'x_measure_spawn_cost__mutmut_74': x_measure_spawn_cost__mutmut_74, 
    'x_measure_spawn_cost__mutmut_75': x_measure_spawn_cost__mutmut_75, 
    'x_measure_spawn_cost__mutmut_76': x_measure_spawn_cost__mutmut_76, 
    'x_measure_spawn_cost__mutmut_77': x_measure_spawn_cost__mutmut_77, 
    'x_measure_spawn_cost__mutmut_78': x_measure_spawn_cost__mutmut_78, 
    'x_measure_spawn_cost__mutmut_79': x_measure_spawn_cost__mutmut_79, 
    'x_measure_spawn_cost__mutmut_80': x_measure_spawn_cost__mutmut_80, 
    'x_measure_spawn_cost__mutmut_81': x_measure_spawn_cost__mutmut_81, 
    'x_measure_spawn_cost__mutmut_82': x_measure_spawn_cost__mutmut_82, 
    'x_measure_spawn_cost__mutmut_83': x_measure_spawn_cost__mutmut_83, 
    'x_measure_spawn_cost__mutmut_84': x_measure_spawn_cost__mutmut_84, 
    'x_measure_spawn_cost__mutmut_85': x_measure_spawn_cost__mutmut_85, 
    'x_measure_spawn_cost__mutmut_86': x_measure_spawn_cost__mutmut_86, 
    'x_measure_spawn_cost__mutmut_87': x_measure_spawn_cost__mutmut_87, 
    'x_measure_spawn_cost__mutmut_88': x_measure_spawn_cost__mutmut_88, 
    'x_measure_spawn_cost__mutmut_89': x_measure_spawn_cost__mutmut_89
}

def measure_spawn_cost(*args, **kwargs):
    result = _mutmut_trampoline(x_measure_spawn_cost__mutmut_orig, x_measure_spawn_cost__mutmut_mutants, args, kwargs)
    return result 

measure_spawn_cost.__signature__ = _mutmut_signature(x_measure_spawn_cost__mutmut_orig)
x_measure_spawn_cost__mutmut_orig.__name__ = 'x_measure_spawn_cost'


def _minimal_worker(x):
    """Minimal no-op worker function for benchmarking chunking overhead."""
    return x


def x_measure_chunking_overhead__mutmut_orig(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_1(timeout: float = 3.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_2(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_3(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_4(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = None

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_5(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 3

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_6(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = None
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_7(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1001
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_8(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = None

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_9(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(None)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_10(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = None
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_11(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 101
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_12(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = None

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_13(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) / large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_14(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize + 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_15(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items - large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_16(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 2) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_17(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = None
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_18(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=None) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_19(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(None)
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_20(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(None, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_21(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, None, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_22(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=None))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_23(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_24(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_25(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, ))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_26(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = None
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_27(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = None

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_28(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large + start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_29(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = None
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_30(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 11
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_31(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = None

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_32(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) / small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_33(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize + 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_34(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items - small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_35(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 2) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_36(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = None
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_37(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=None) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_38(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(None)
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_39(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(None, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_40(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, None, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_41(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=None))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_42(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_43(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_44(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, ))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_45(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = None
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_46(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = None

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_47(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small + start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_48(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = None
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_49(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small + time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_50(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = None

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_51(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks + num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_52(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 or time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_53(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff >= 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_54(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 1 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_55(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff >= 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_56(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 1:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_57(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = None

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_58(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff * chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_59(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_60(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (1 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_61(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 <= per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_62(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead <= 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_63(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 1.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_64(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = None
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_65(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small <= time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_66(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large / 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_67(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 2.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_68(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = None
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_69(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = None
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_70(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead / num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_71(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead >= time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_72(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small / 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_73(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 1.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_74(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = None
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_75(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_76(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (1.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_77(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 <= per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_78(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead <= 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_79(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 1.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_80(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = None
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_81(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = None
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_82(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = None
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD


def x_measure_chunking_overhead__mutmut_83(timeout: float = 2.0) -> float:
    """
    Measure the per-chunk overhead for task distribution in multiprocessing.Pool.

    This function measures the marginal cost of task distribution overhead by
    comparing execution with different chunk sizes. The overhead comes from:
    - Queue operations for task distribution
    - Context switches between workers
    - Task scheduling and management

    The measurement is cached globally to avoid repeated benchmarking.
    Thread-safe: Uses lock to prevent concurrent measurements.

    Args:
        timeout: Maximum time to wait for measurement in seconds

    Returns:
        Measured per-chunk overhead in seconds, or default estimate on failure

    Algorithm:
        1. Execute workload with large chunks (fewer chunks, less overhead)
        2. Execute workload with small chunks (more chunks, more overhead)
        3. Calculate marginal cost: (time_small - time_large) / (chunks_small - chunks_large)
        4. Validate measurement quality with multiple criteria
        5. Use intelligent fallback if measurement is unreliable

        This isolates the per-chunk overhead from the actual computation time.

    Improvements:
        - Multiple validation checks for measurement quality
        - Detects and handles measurement noise
        - Adaptive chunk size selection
        - More robust fallback strategies

    Fallback Strategy:
        If benchmarking fails or produces unreliable results, falls back to
        the default estimate (0.5ms per chunk).

    Thread Safety:
        Uses a lock to ensure only one thread performs the measurement. If
        multiple threads call this function simultaneously, the first one
        performs the measurement while others wait for the result.
    """
    global _CACHED_CHUNKING_OVERHEAD

    # Quick check without lock (optimization for common case)
    if _CACHED_CHUNKING_OVERHEAD is not None:
        return _CACHED_CHUNKING_OVERHEAD

    # Acquire lock for measurement
    with _chunking_overhead_lock:
        # Double-check after acquiring lock (another thread may have measured)
        if _CACHED_CHUNKING_OVERHEAD is not None:
            return _CACHED_CHUNKING_OVERHEAD

        # Perform measurement (only one thread reaches here)
        try:
            # Use 2 workers for consistency with real use cases
            n_workers = 2

            # Use a reasonable workload size
            total_items = 1000
            data = range(total_items)

            # Test with large chunks (fewer chunks, less overhead)
            # Use chunks of 100 items -> 10 chunks
            large_chunksize = 100
            num_large_chunks = (total_items + large_chunksize - 1) // large_chunksize

            start_large = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=large_chunksize))
            end_large = time.perf_counter()
            time_large = end_large - start_large

            # Test with small chunks (more chunks, more overhead)
            # Use chunks of 10 items -> 100 chunks
            small_chunksize = 10
            num_small_chunks = (total_items + small_chunksize - 1) // small_chunksize

            start_small = time.perf_counter()
            with multiprocessing.Pool(processes=n_workers) as pool:
                list(pool.map(_minimal_worker, data, chunksize=small_chunksize))
            end_small = time.perf_counter()
            time_small = end_small - start_small

            # Calculate marginal cost per chunk
            # Difference in execution time divided by difference in number of chunks
            time_diff = time_small - time_large
            chunk_diff = num_small_chunks - num_large_chunks

            # Enhanced validation: Check multiple quality criteria
            if chunk_diff > 0 and time_diff > 0:
                per_chunk_overhead = time_diff / chunk_diff

                # Quality check 1: Overhead should be positive and reasonable (< 10ms per chunk)
                if not (0 < per_chunk_overhead < 0.01):
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 2: Measurement should show clear signal
                # The small-chunk run should take at least 5% longer than large-chunk
                # This ensures we're measuring real overhead, not noise
                if time_small < time_large * 1.05:
                    # Signal too weak - likely measurement noise
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 3: Per-chunk overhead should be reasonable fraction of total time
                # If per-chunk overhead * num_chunks > 50% of total time, something is wrong
                estimated_total_overhead = per_chunk_overhead * num_small_chunks
                if estimated_total_overhead > time_small * 0.5:
                    # Overhead seems unrealistically high
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # Quality check 4: The overhead should be in a reasonable range
                # Based on empirical observations, overhead is typically 0.1ms to 5ms per chunk
                if not (0.0001 < per_chunk_overhead < 0.005):
                    # Outside reasonable bounds - use default
                    _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
                    return DEFAULT_CHUNKING_OVERHEAD

                # All quality checks passed - use measured value
                _CACHED_CHUNKING_OVERHEAD = per_chunk_overhead
                return per_chunk_overhead

            # If measurement conditions not met, fall back to default
            _CACHED_CHUNKING_OVERHEAD = DEFAULT_CHUNKING_OVERHEAD
            return DEFAULT_CHUNKING_OVERHEAD

        except (OSError, TimeoutError, ValueError, multiprocessing.ProcessError):
            # If measurement fails, fall back to default estimate
            _CACHED_CHUNKING_OVERHEAD = None
            return DEFAULT_CHUNKING_OVERHEAD

x_measure_chunking_overhead__mutmut_mutants : ClassVar[MutantDict] = {
'x_measure_chunking_overhead__mutmut_1': x_measure_chunking_overhead__mutmut_1, 
    'x_measure_chunking_overhead__mutmut_2': x_measure_chunking_overhead__mutmut_2, 
    'x_measure_chunking_overhead__mutmut_3': x_measure_chunking_overhead__mutmut_3, 
    'x_measure_chunking_overhead__mutmut_4': x_measure_chunking_overhead__mutmut_4, 
    'x_measure_chunking_overhead__mutmut_5': x_measure_chunking_overhead__mutmut_5, 
    'x_measure_chunking_overhead__mutmut_6': x_measure_chunking_overhead__mutmut_6, 
    'x_measure_chunking_overhead__mutmut_7': x_measure_chunking_overhead__mutmut_7, 
    'x_measure_chunking_overhead__mutmut_8': x_measure_chunking_overhead__mutmut_8, 
    'x_measure_chunking_overhead__mutmut_9': x_measure_chunking_overhead__mutmut_9, 
    'x_measure_chunking_overhead__mutmut_10': x_measure_chunking_overhead__mutmut_10, 
    'x_measure_chunking_overhead__mutmut_11': x_measure_chunking_overhead__mutmut_11, 
    'x_measure_chunking_overhead__mutmut_12': x_measure_chunking_overhead__mutmut_12, 
    'x_measure_chunking_overhead__mutmut_13': x_measure_chunking_overhead__mutmut_13, 
    'x_measure_chunking_overhead__mutmut_14': x_measure_chunking_overhead__mutmut_14, 
    'x_measure_chunking_overhead__mutmut_15': x_measure_chunking_overhead__mutmut_15, 
    'x_measure_chunking_overhead__mutmut_16': x_measure_chunking_overhead__mutmut_16, 
    'x_measure_chunking_overhead__mutmut_17': x_measure_chunking_overhead__mutmut_17, 
    'x_measure_chunking_overhead__mutmut_18': x_measure_chunking_overhead__mutmut_18, 
    'x_measure_chunking_overhead__mutmut_19': x_measure_chunking_overhead__mutmut_19, 
    'x_measure_chunking_overhead__mutmut_20': x_measure_chunking_overhead__mutmut_20, 
    'x_measure_chunking_overhead__mutmut_21': x_measure_chunking_overhead__mutmut_21, 
    'x_measure_chunking_overhead__mutmut_22': x_measure_chunking_overhead__mutmut_22, 
    'x_measure_chunking_overhead__mutmut_23': x_measure_chunking_overhead__mutmut_23, 
    'x_measure_chunking_overhead__mutmut_24': x_measure_chunking_overhead__mutmut_24, 
    'x_measure_chunking_overhead__mutmut_25': x_measure_chunking_overhead__mutmut_25, 
    'x_measure_chunking_overhead__mutmut_26': x_measure_chunking_overhead__mutmut_26, 
    'x_measure_chunking_overhead__mutmut_27': x_measure_chunking_overhead__mutmut_27, 
    'x_measure_chunking_overhead__mutmut_28': x_measure_chunking_overhead__mutmut_28, 
    'x_measure_chunking_overhead__mutmut_29': x_measure_chunking_overhead__mutmut_29, 
    'x_measure_chunking_overhead__mutmut_30': x_measure_chunking_overhead__mutmut_30, 
    'x_measure_chunking_overhead__mutmut_31': x_measure_chunking_overhead__mutmut_31, 
    'x_measure_chunking_overhead__mutmut_32': x_measure_chunking_overhead__mutmut_32, 
    'x_measure_chunking_overhead__mutmut_33': x_measure_chunking_overhead__mutmut_33, 
    'x_measure_chunking_overhead__mutmut_34': x_measure_chunking_overhead__mutmut_34, 
    'x_measure_chunking_overhead__mutmut_35': x_measure_chunking_overhead__mutmut_35, 
    'x_measure_chunking_overhead__mutmut_36': x_measure_chunking_overhead__mutmut_36, 
    'x_measure_chunking_overhead__mutmut_37': x_measure_chunking_overhead__mutmut_37, 
    'x_measure_chunking_overhead__mutmut_38': x_measure_chunking_overhead__mutmut_38, 
    'x_measure_chunking_overhead__mutmut_39': x_measure_chunking_overhead__mutmut_39, 
    'x_measure_chunking_overhead__mutmut_40': x_measure_chunking_overhead__mutmut_40, 
    'x_measure_chunking_overhead__mutmut_41': x_measure_chunking_overhead__mutmut_41, 
    'x_measure_chunking_overhead__mutmut_42': x_measure_chunking_overhead__mutmut_42, 
    'x_measure_chunking_overhead__mutmut_43': x_measure_chunking_overhead__mutmut_43, 
    'x_measure_chunking_overhead__mutmut_44': x_measure_chunking_overhead__mutmut_44, 
    'x_measure_chunking_overhead__mutmut_45': x_measure_chunking_overhead__mutmut_45, 
    'x_measure_chunking_overhead__mutmut_46': x_measure_chunking_overhead__mutmut_46, 
    'x_measure_chunking_overhead__mutmut_47': x_measure_chunking_overhead__mutmut_47, 
    'x_measure_chunking_overhead__mutmut_48': x_measure_chunking_overhead__mutmut_48, 
    'x_measure_chunking_overhead__mutmut_49': x_measure_chunking_overhead__mutmut_49, 
    'x_measure_chunking_overhead__mutmut_50': x_measure_chunking_overhead__mutmut_50, 
    'x_measure_chunking_overhead__mutmut_51': x_measure_chunking_overhead__mutmut_51, 
    'x_measure_chunking_overhead__mutmut_52': x_measure_chunking_overhead__mutmut_52, 
    'x_measure_chunking_overhead__mutmut_53': x_measure_chunking_overhead__mutmut_53, 
    'x_measure_chunking_overhead__mutmut_54': x_measure_chunking_overhead__mutmut_54, 
    'x_measure_chunking_overhead__mutmut_55': x_measure_chunking_overhead__mutmut_55, 
    'x_measure_chunking_overhead__mutmut_56': x_measure_chunking_overhead__mutmut_56, 
    'x_measure_chunking_overhead__mutmut_57': x_measure_chunking_overhead__mutmut_57, 
    'x_measure_chunking_overhead__mutmut_58': x_measure_chunking_overhead__mutmut_58, 
    'x_measure_chunking_overhead__mutmut_59': x_measure_chunking_overhead__mutmut_59, 
    'x_measure_chunking_overhead__mutmut_60': x_measure_chunking_overhead__mutmut_60, 
    'x_measure_chunking_overhead__mutmut_61': x_measure_chunking_overhead__mutmut_61, 
    'x_measure_chunking_overhead__mutmut_62': x_measure_chunking_overhead__mutmut_62, 
    'x_measure_chunking_overhead__mutmut_63': x_measure_chunking_overhead__mutmut_63, 
    'x_measure_chunking_overhead__mutmut_64': x_measure_chunking_overhead__mutmut_64, 
    'x_measure_chunking_overhead__mutmut_65': x_measure_chunking_overhead__mutmut_65, 
    'x_measure_chunking_overhead__mutmut_66': x_measure_chunking_overhead__mutmut_66, 
    'x_measure_chunking_overhead__mutmut_67': x_measure_chunking_overhead__mutmut_67, 
    'x_measure_chunking_overhead__mutmut_68': x_measure_chunking_overhead__mutmut_68, 
    'x_measure_chunking_overhead__mutmut_69': x_measure_chunking_overhead__mutmut_69, 
    'x_measure_chunking_overhead__mutmut_70': x_measure_chunking_overhead__mutmut_70, 
    'x_measure_chunking_overhead__mutmut_71': x_measure_chunking_overhead__mutmut_71, 
    'x_measure_chunking_overhead__mutmut_72': x_measure_chunking_overhead__mutmut_72, 
    'x_measure_chunking_overhead__mutmut_73': x_measure_chunking_overhead__mutmut_73, 
    'x_measure_chunking_overhead__mutmut_74': x_measure_chunking_overhead__mutmut_74, 
    'x_measure_chunking_overhead__mutmut_75': x_measure_chunking_overhead__mutmut_75, 
    'x_measure_chunking_overhead__mutmut_76': x_measure_chunking_overhead__mutmut_76, 
    'x_measure_chunking_overhead__mutmut_77': x_measure_chunking_overhead__mutmut_77, 
    'x_measure_chunking_overhead__mutmut_78': x_measure_chunking_overhead__mutmut_78, 
    'x_measure_chunking_overhead__mutmut_79': x_measure_chunking_overhead__mutmut_79, 
    'x_measure_chunking_overhead__mutmut_80': x_measure_chunking_overhead__mutmut_80, 
    'x_measure_chunking_overhead__mutmut_81': x_measure_chunking_overhead__mutmut_81, 
    'x_measure_chunking_overhead__mutmut_82': x_measure_chunking_overhead__mutmut_82, 
    'x_measure_chunking_overhead__mutmut_83': x_measure_chunking_overhead__mutmut_83
}

def measure_chunking_overhead(*args, **kwargs):
    result = _mutmut_trampoline(x_measure_chunking_overhead__mutmut_orig, x_measure_chunking_overhead__mutmut_mutants, args, kwargs)
    return result 

measure_chunking_overhead.__signature__ = _mutmut_signature(x_measure_chunking_overhead__mutmut_orig)
x_measure_chunking_overhead__mutmut_orig.__name__ = 'x_measure_chunking_overhead'


def x_get_chunking_overhead__mutmut_orig(use_benchmark: bool = True) -> float:
    """
    Get the per-chunk overhead, either measured or estimated.

    Args:
        use_benchmark: If True, measures actual chunking overhead. If False,
                      uses default estimate. Default is True for accuracy
                      as measurements are fast (~10ms) and cached globally.

    Returns:
        Chunking overhead in seconds per chunk
    """
    if use_benchmark:
        return measure_chunking_overhead()
    else:
        return DEFAULT_CHUNKING_OVERHEAD


def x_get_chunking_overhead__mutmut_1(use_benchmark: bool = False) -> float:
    """
    Get the per-chunk overhead, either measured or estimated.

    Args:
        use_benchmark: If True, measures actual chunking overhead. If False,
                      uses default estimate. Default is True for accuracy
                      as measurements are fast (~10ms) and cached globally.

    Returns:
        Chunking overhead in seconds per chunk
    """
    if use_benchmark:
        return measure_chunking_overhead()
    else:
        return DEFAULT_CHUNKING_OVERHEAD

x_get_chunking_overhead__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_chunking_overhead__mutmut_1': x_get_chunking_overhead__mutmut_1
}

def get_chunking_overhead(*args, **kwargs):
    result = _mutmut_trampoline(x_get_chunking_overhead__mutmut_orig, x_get_chunking_overhead__mutmut_mutants, args, kwargs)
    return result 

get_chunking_overhead.__signature__ = _mutmut_signature(x_get_chunking_overhead__mutmut_orig)
x_get_chunking_overhead__mutmut_orig.__name__ = 'x_get_chunking_overhead'


def x_get_multiprocessing_start_method__mutmut_orig() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=True)

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_1() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=True)

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_2() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=True)

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_3() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = ""
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=True)

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_4() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = None
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=True)

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_5() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = None

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_6() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=None)

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_7() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=False)

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_8() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=True)

        # If still None, return the OS default
        if method is not None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_9() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=True)

        # If still None, return the OS default
        if method is None:
            method = None

        # Cache the result
        _CACHED_START_METHOD = method
        return _CACHED_START_METHOD


def x_get_multiprocessing_start_method__mutmut_10() -> str:
    """
    Get the current multiprocessing start method with caching for performance.

    The start method is constant during program execution (set once at startup),
    so caching it avoids repeated calls to multiprocessing.get_start_method()
    and platform detection logic.

    Thread-safe: Uses lock to prevent race conditions during initialization.

    Returns:
        The current start method name ('fork', 'spawn', or 'forkserver')

    Rationale:
        The start method determines how child processes are created:
        - 'fork': Uses fork() (fast, Linux/Unix default, not available on Windows)
        - 'spawn': Starts fresh interpreter (slow, Windows/macOS default, safest)
        - 'forkserver': Uses a server process (middle ground, Unix only)

    Note:
        Users can override the default with multiprocessing.set_start_method().
        This function detects the actual method being used, not the OS default.

    Performance Impact:
        - First call: Full multiprocessing query and platform fallback (~4.71s on Linux)
        - Subsequent calls: Direct return of cached string (~0.09s)
        - Called 4 times per optimize() invocation, providing measurable speedup
          (savings of ~13.86s per optimize() call)
    """
    global _CACHED_START_METHOD

    # Quick check without lock (optimization for common case)
    if _CACHED_START_METHOD is not None:
        return _CACHED_START_METHOD

    # Acquire lock for initialization
    with _start_method_lock:
        # Double-check after acquiring lock (another thread may have initialized)
        if _CACHED_START_METHOD is not None:
            return _CACHED_START_METHOD

        # Perform initialization (only one thread reaches here)
        # Try to get the start method, allowing None if not yet initialized
        method = None
        try:
            method = multiprocessing.get_start_method()
        except RuntimeError:
            # Context not initialized yet
            method = multiprocessing.get_start_method(allow_none=True)

        # If still None, return the OS default
        if method is None:
            method = _get_default_start_method()

        # Cache the result
        _CACHED_START_METHOD = None
        return _CACHED_START_METHOD

x_get_multiprocessing_start_method__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_multiprocessing_start_method__mutmut_1': x_get_multiprocessing_start_method__mutmut_1, 
    'x_get_multiprocessing_start_method__mutmut_2': x_get_multiprocessing_start_method__mutmut_2, 
    'x_get_multiprocessing_start_method__mutmut_3': x_get_multiprocessing_start_method__mutmut_3, 
    'x_get_multiprocessing_start_method__mutmut_4': x_get_multiprocessing_start_method__mutmut_4, 
    'x_get_multiprocessing_start_method__mutmut_5': x_get_multiprocessing_start_method__mutmut_5, 
    'x_get_multiprocessing_start_method__mutmut_6': x_get_multiprocessing_start_method__mutmut_6, 
    'x_get_multiprocessing_start_method__mutmut_7': x_get_multiprocessing_start_method__mutmut_7, 
    'x_get_multiprocessing_start_method__mutmut_8': x_get_multiprocessing_start_method__mutmut_8, 
    'x_get_multiprocessing_start_method__mutmut_9': x_get_multiprocessing_start_method__mutmut_9, 
    'x_get_multiprocessing_start_method__mutmut_10': x_get_multiprocessing_start_method__mutmut_10
}

def get_multiprocessing_start_method(*args, **kwargs):
    result = _mutmut_trampoline(x_get_multiprocessing_start_method__mutmut_orig, x_get_multiprocessing_start_method__mutmut_mutants, args, kwargs)
    return result 

get_multiprocessing_start_method.__signature__ = _mutmut_signature(x_get_multiprocessing_start_method__mutmut_orig)
x_get_multiprocessing_start_method__mutmut_orig.__name__ = 'x_get_multiprocessing_start_method'


def x__get_default_start_method__mutmut_orig() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_1() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = None

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_2() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system != "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_3() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "XXWindowsXX":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_4() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_5() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "WINDOWS":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_6() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "XXspawnXX"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_7() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "SPAWN"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_8() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system != "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_9() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "XXDarwinXX":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_10() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_11() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "DARWIN":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_12() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info > (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_13() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (4, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_14() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 9):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_15() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "XXspawnXX"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_16() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "SPAWN"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_17() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "XXforkXX"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_18() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "FORK"
    else:
        # Linux and other Unix systems default to fork
        return "fork"


def x__get_default_start_method__mutmut_19() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "XXforkXX"


def x__get_default_start_method__mutmut_20() -> str:
    """
    Get the default multiprocessing start method for the current OS.

    Returns:
        Default start method name for the current platform

    OS Defaults:
        - Linux/Unix: 'fork'
        - Windows: 'spawn'
        - macOS (Python >= 3.8): 'spawn'
        - macOS (Python < 3.8): 'fork'
    """
    system = platform.system()

    if system == "Windows":
        return "spawn"
    elif system == "Darwin":
        # macOS changed default from fork to spawn in Python 3.8
        if sys.version_info >= (3, 8):
            return "spawn"
        else:
            return "fork"
    else:
        # Linux and other Unix systems default to fork
        return "FORK"

x__get_default_start_method__mutmut_mutants : ClassVar[MutantDict] = {
'x__get_default_start_method__mutmut_1': x__get_default_start_method__mutmut_1, 
    'x__get_default_start_method__mutmut_2': x__get_default_start_method__mutmut_2, 
    'x__get_default_start_method__mutmut_3': x__get_default_start_method__mutmut_3, 
    'x__get_default_start_method__mutmut_4': x__get_default_start_method__mutmut_4, 
    'x__get_default_start_method__mutmut_5': x__get_default_start_method__mutmut_5, 
    'x__get_default_start_method__mutmut_6': x__get_default_start_method__mutmut_6, 
    'x__get_default_start_method__mutmut_7': x__get_default_start_method__mutmut_7, 
    'x__get_default_start_method__mutmut_8': x__get_default_start_method__mutmut_8, 
    'x__get_default_start_method__mutmut_9': x__get_default_start_method__mutmut_9, 
    'x__get_default_start_method__mutmut_10': x__get_default_start_method__mutmut_10, 
    'x__get_default_start_method__mutmut_11': x__get_default_start_method__mutmut_11, 
    'x__get_default_start_method__mutmut_12': x__get_default_start_method__mutmut_12, 
    'x__get_default_start_method__mutmut_13': x__get_default_start_method__mutmut_13, 
    'x__get_default_start_method__mutmut_14': x__get_default_start_method__mutmut_14, 
    'x__get_default_start_method__mutmut_15': x__get_default_start_method__mutmut_15, 
    'x__get_default_start_method__mutmut_16': x__get_default_start_method__mutmut_16, 
    'x__get_default_start_method__mutmut_17': x__get_default_start_method__mutmut_17, 
    'x__get_default_start_method__mutmut_18': x__get_default_start_method__mutmut_18, 
    'x__get_default_start_method__mutmut_19': x__get_default_start_method__mutmut_19, 
    'x__get_default_start_method__mutmut_20': x__get_default_start_method__mutmut_20
}

def _get_default_start_method(*args, **kwargs):
    result = _mutmut_trampoline(x__get_default_start_method__mutmut_orig, x__get_default_start_method__mutmut_mutants, args, kwargs)
    return result 

_get_default_start_method.__signature__ = _mutmut_signature(x__get_default_start_method__mutmut_orig)
x__get_default_start_method__mutmut_orig.__name__ = 'x__get_default_start_method'


def x_get_spawn_cost_estimate__mutmut_orig() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_1() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = None

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_2() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method != "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_3() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "XXforkXX":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_4() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "FORK":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_5() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method != "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_6() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "XXspawnXX":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_7() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "SPAWN":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_8() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method != "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_9() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "XXforkserverXX":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_10() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "FORKSERVER":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_11() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) * 2


def x_get_spawn_cost_estimate__mutmut_12() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK - SPAWN_COST_SPAWN) / 2


def x_get_spawn_cost_estimate__mutmut_13() -> float:
    """
    Estimate the process spawn cost based on actual start method.

    This is a fallback when actual measurement is not possible.

    Returns:
        Estimated spawn cost in seconds based on start method

    Rationale:
        - fork: Uses fork() with copy-on-write, very fast (~10-15ms measured)
        - spawn: Starts fresh interpreter, requires module imports (~200ms)
        - forkserver: Server process + fork, middle ground (~50-100ms)

    Important:
        This function now checks the ACTUAL start method being used,
        not just the OS. A user can set spawn on Linux, making spawn
        cost 13x higher than the old OS-based estimate would suggest.
    """
    start_method = get_multiprocessing_start_method()

    if start_method == "fork":
        # Fork with Copy-on-Write - very fast
        return SPAWN_COST_FORK
    elif start_method == "spawn":
        # Spawn requires full interpreter initialization
        return SPAWN_COST_SPAWN
    elif start_method == "forkserver":
        # Forkserver uses a pre-started server process, faster than spawn
        # but slower than direct fork
        return SPAWN_COST_FORKSERVER
    else:
        # Unknown method - use conservative estimate (halfway between fork and spawn)
        return (SPAWN_COST_FORK + SPAWN_COST_SPAWN) / 3

x_get_spawn_cost_estimate__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_spawn_cost_estimate__mutmut_1': x_get_spawn_cost_estimate__mutmut_1, 
    'x_get_spawn_cost_estimate__mutmut_2': x_get_spawn_cost_estimate__mutmut_2, 
    'x_get_spawn_cost_estimate__mutmut_3': x_get_spawn_cost_estimate__mutmut_3, 
    'x_get_spawn_cost_estimate__mutmut_4': x_get_spawn_cost_estimate__mutmut_4, 
    'x_get_spawn_cost_estimate__mutmut_5': x_get_spawn_cost_estimate__mutmut_5, 
    'x_get_spawn_cost_estimate__mutmut_6': x_get_spawn_cost_estimate__mutmut_6, 
    'x_get_spawn_cost_estimate__mutmut_7': x_get_spawn_cost_estimate__mutmut_7, 
    'x_get_spawn_cost_estimate__mutmut_8': x_get_spawn_cost_estimate__mutmut_8, 
    'x_get_spawn_cost_estimate__mutmut_9': x_get_spawn_cost_estimate__mutmut_9, 
    'x_get_spawn_cost_estimate__mutmut_10': x_get_spawn_cost_estimate__mutmut_10, 
    'x_get_spawn_cost_estimate__mutmut_11': x_get_spawn_cost_estimate__mutmut_11, 
    'x_get_spawn_cost_estimate__mutmut_12': x_get_spawn_cost_estimate__mutmut_12, 
    'x_get_spawn_cost_estimate__mutmut_13': x_get_spawn_cost_estimate__mutmut_13
}

def get_spawn_cost_estimate(*args, **kwargs):
    result = _mutmut_trampoline(x_get_spawn_cost_estimate__mutmut_orig, x_get_spawn_cost_estimate__mutmut_mutants, args, kwargs)
    return result 

get_spawn_cost_estimate.__signature__ = _mutmut_signature(x_get_spawn_cost_estimate__mutmut_orig)
x_get_spawn_cost_estimate__mutmut_orig.__name__ = 'x_get_spawn_cost_estimate'


def x_get_spawn_cost__mutmut_orig(use_benchmark: bool = True) -> float:
    """
    Get the process spawn cost, either measured or estimated.

    Args:
        use_benchmark: If True, measures actual spawn cost. If False,
                      uses start-method-based estimate. Default is True
                      for accuracy as measurements are fast (~15ms) and
                      cached globally.

    Returns:
        Spawn cost in seconds
    """
    if use_benchmark:
        return measure_spawn_cost()
    else:
        return get_spawn_cost_estimate()


def x_get_spawn_cost__mutmut_1(use_benchmark: bool = False) -> float:
    """
    Get the process spawn cost, either measured or estimated.

    Args:
        use_benchmark: If True, measures actual spawn cost. If False,
                      uses start-method-based estimate. Default is True
                      for accuracy as measurements are fast (~15ms) and
                      cached globally.

    Returns:
        Spawn cost in seconds
    """
    if use_benchmark:
        return measure_spawn_cost()
    else:
        return get_spawn_cost_estimate()

x_get_spawn_cost__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_spawn_cost__mutmut_1': x_get_spawn_cost__mutmut_1
}

def get_spawn_cost(*args, **kwargs):
    result = _mutmut_trampoline(x_get_spawn_cost__mutmut_orig, x_get_spawn_cost__mutmut_mutants, args, kwargs)
    return result 

get_spawn_cost.__signature__ = _mutmut_signature(x_get_spawn_cost__mutmut_orig)
x_get_spawn_cost__mutmut_orig.__name__ = 'x_get_spawn_cost'


def x_check_start_method_mismatch__mutmut_orig() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_1() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = None
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_2() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = None

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_3() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual == default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_4() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" or default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_5() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual != "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_6() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "XXspawnXX" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_7() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "SPAWN" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_8() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default != "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_9() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "XXforkXX":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_10() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "FORK":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_11() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return False, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_12() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(None)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_13() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK / 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_14() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1001)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_15() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(None)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_16() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN / 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_17() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1001)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_18() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" or default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_19() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual != "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_20() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "XXforkXX" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_21() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "FORK" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_22() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default != "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_23() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "XXspawnXX":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_24() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "SPAWN":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_25() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return False, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_26() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(None)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_27() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK / 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_28() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1001)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_29() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(None)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_30() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN / 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_31() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1001)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_32() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return False, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return False, None


def x_check_start_method_mismatch__mutmut_33() -> Tuple[bool, Optional[str]]:
    """
    Check if the current start method differs from the OS default.

    Returns:
        Tuple of (is_mismatch, warning_message) where:
        - is_mismatch: True if start method differs from OS default
        - warning_message: Explanation of the mismatch (None if no mismatch)

    Use Case:
        This detects when users have explicitly set a non-default start method,
        which can significantly affect spawn costs and optimization decisions.

        Example: User sets 'spawn' on Linux for safety reasons, but this makes
        spawning 13x slower (200ms vs 15ms), changing optimal parallelization.
    """
    actual = get_multiprocessing_start_method()
    default = _get_default_start_method()

    if actual != default:
        if actual == "spawn" and default == "fork":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This increases spawn cost from ~{int(SPAWN_COST_FORK * 1000)}ms to ~{int(SPAWN_COST_SPAWN * 1000)}ms per worker. "
                f"Consider using 'fork' or 'forkserver' for better performance."
            )
        elif actual == "fork" and default == "spawn":
            return True, (
                f"Using '{actual}' start method on a system that defaults to '{default}'. "
                f"This is faster but may have issues with threads or locks. "
                f"Spawn cost estimates adjusted accordingly (~{int(SPAWN_COST_FORK * 1000)}ms vs ~{int(SPAWN_COST_SPAWN * 1000)}ms)."
            )
        else:
            return True, (
                f"Using '{actual}' start method instead of OS default '{default}'. "
                f"Spawn cost estimates have been adjusted."
            )

    return True, None

x_check_start_method_mismatch__mutmut_mutants : ClassVar[MutantDict] = {
'x_check_start_method_mismatch__mutmut_1': x_check_start_method_mismatch__mutmut_1, 
    'x_check_start_method_mismatch__mutmut_2': x_check_start_method_mismatch__mutmut_2, 
    'x_check_start_method_mismatch__mutmut_3': x_check_start_method_mismatch__mutmut_3, 
    'x_check_start_method_mismatch__mutmut_4': x_check_start_method_mismatch__mutmut_4, 
    'x_check_start_method_mismatch__mutmut_5': x_check_start_method_mismatch__mutmut_5, 
    'x_check_start_method_mismatch__mutmut_6': x_check_start_method_mismatch__mutmut_6, 
    'x_check_start_method_mismatch__mutmut_7': x_check_start_method_mismatch__mutmut_7, 
    'x_check_start_method_mismatch__mutmut_8': x_check_start_method_mismatch__mutmut_8, 
    'x_check_start_method_mismatch__mutmut_9': x_check_start_method_mismatch__mutmut_9, 
    'x_check_start_method_mismatch__mutmut_10': x_check_start_method_mismatch__mutmut_10, 
    'x_check_start_method_mismatch__mutmut_11': x_check_start_method_mismatch__mutmut_11, 
    'x_check_start_method_mismatch__mutmut_12': x_check_start_method_mismatch__mutmut_12, 
    'x_check_start_method_mismatch__mutmut_13': x_check_start_method_mismatch__mutmut_13, 
    'x_check_start_method_mismatch__mutmut_14': x_check_start_method_mismatch__mutmut_14, 
    'x_check_start_method_mismatch__mutmut_15': x_check_start_method_mismatch__mutmut_15, 
    'x_check_start_method_mismatch__mutmut_16': x_check_start_method_mismatch__mutmut_16, 
    'x_check_start_method_mismatch__mutmut_17': x_check_start_method_mismatch__mutmut_17, 
    'x_check_start_method_mismatch__mutmut_18': x_check_start_method_mismatch__mutmut_18, 
    'x_check_start_method_mismatch__mutmut_19': x_check_start_method_mismatch__mutmut_19, 
    'x_check_start_method_mismatch__mutmut_20': x_check_start_method_mismatch__mutmut_20, 
    'x_check_start_method_mismatch__mutmut_21': x_check_start_method_mismatch__mutmut_21, 
    'x_check_start_method_mismatch__mutmut_22': x_check_start_method_mismatch__mutmut_22, 
    'x_check_start_method_mismatch__mutmut_23': x_check_start_method_mismatch__mutmut_23, 
    'x_check_start_method_mismatch__mutmut_24': x_check_start_method_mismatch__mutmut_24, 
    'x_check_start_method_mismatch__mutmut_25': x_check_start_method_mismatch__mutmut_25, 
    'x_check_start_method_mismatch__mutmut_26': x_check_start_method_mismatch__mutmut_26, 
    'x_check_start_method_mismatch__mutmut_27': x_check_start_method_mismatch__mutmut_27, 
    'x_check_start_method_mismatch__mutmut_28': x_check_start_method_mismatch__mutmut_28, 
    'x_check_start_method_mismatch__mutmut_29': x_check_start_method_mismatch__mutmut_29, 
    'x_check_start_method_mismatch__mutmut_30': x_check_start_method_mismatch__mutmut_30, 
    'x_check_start_method_mismatch__mutmut_31': x_check_start_method_mismatch__mutmut_31, 
    'x_check_start_method_mismatch__mutmut_32': x_check_start_method_mismatch__mutmut_32, 
    'x_check_start_method_mismatch__mutmut_33': x_check_start_method_mismatch__mutmut_33
}

def check_start_method_mismatch(*args, **kwargs):
    result = _mutmut_trampoline(x_check_start_method_mismatch__mutmut_orig, x_check_start_method_mismatch__mutmut_mutants, args, kwargs)
    return result 

check_start_method_mismatch.__signature__ = _mutmut_signature(x_check_start_method_mismatch__mutmut_orig)
x_check_start_method_mismatch__mutmut_orig.__name__ = 'x_check_start_method_mismatch'


def x__read_cgroup_v2_limit__mutmut_orig(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_1(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = ""
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_2(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = ""

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_3(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = None
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_4(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(None, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_5(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, None)
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_6(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join("memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_7(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, )
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_8(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "XXmemory.maxXX")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_9(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "MEMORY.MAX")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_10(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(None):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_11(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(None, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_12(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, None) as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_13(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open('r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_14(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, ) as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_15(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'XXrXX') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_16(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'R') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_17(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = None
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_18(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value == "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_19(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "XXmaxXX":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_20(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "MAX":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_21(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = None
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_22(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(None)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_23(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = None
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_24(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(None, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_25(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, None)
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_26(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join("memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_27(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, )
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_28(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "XXmemory.highXX")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_29(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "MEMORY.HIGH")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_30(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(None):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_31(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(None, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_32(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, None) as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_33(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open('r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_34(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, ) as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_35(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'XXrXX') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_36(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'R') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_37(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = None
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_38(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value == "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_39(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "XXmaxXX":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_40(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "MAX":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_41(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = None
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_42(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(None)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_43(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None or high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_44(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_45(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_46(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(None, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_47(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, None)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_48(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_49(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, )
    elif max_limit is not None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_50(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is None:
        return max_limit
    elif high_limit is not None:
        return high_limit

    return None


def x__read_cgroup_v2_limit__mutmut_51(base_path: str) -> Optional[int]:
    """
    Read memory limit from cgroup v2 unified hierarchy.

    Args:
        base_path: Base path to check (e.g., "/sys/fs/cgroup")

    Returns:
        Memory limit in bytes, or None if not found or invalid

    Algorithm:
        1. Check memory.max (hard limit)
        2. Check memory.high (soft limit - use if lower than max)
        3. Return the most restrictive limit

    Note:
        In cgroup v2, memory.high is a "soft" limit where the kernel
        will throttle but not kill. memory.max is the "hard" limit where
        OOM kills happen. We respect both to be conservative.
    """
    max_limit = None
    high_limit = None

    # Check memory.max (hard limit)
    max_path = os.path.join(base_path, "memory.max")
    if os.path.exists(max_path):
        try:
            with open(max_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    max_limit = int(value)
        except (IOError, ValueError):
            pass

    # Check memory.high (soft limit)
    high_path = os.path.join(base_path, "memory.high")
    if os.path.exists(high_path):
        try:
            with open(high_path, 'r') as f:
                value = f.read().strip()
                # "max" means no limit
                if value != "max":
                    high_limit = int(value)
        except (IOError, ValueError):
            pass

    # Return the most restrictive limit
    if max_limit is not None and high_limit is not None:
        return min(max_limit, high_limit)
    elif max_limit is not None:
        return max_limit
    elif high_limit is None:
        return high_limit

    return None

x__read_cgroup_v2_limit__mutmut_mutants : ClassVar[MutantDict] = {
'x__read_cgroup_v2_limit__mutmut_1': x__read_cgroup_v2_limit__mutmut_1, 
    'x__read_cgroup_v2_limit__mutmut_2': x__read_cgroup_v2_limit__mutmut_2, 
    'x__read_cgroup_v2_limit__mutmut_3': x__read_cgroup_v2_limit__mutmut_3, 
    'x__read_cgroup_v2_limit__mutmut_4': x__read_cgroup_v2_limit__mutmut_4, 
    'x__read_cgroup_v2_limit__mutmut_5': x__read_cgroup_v2_limit__mutmut_5, 
    'x__read_cgroup_v2_limit__mutmut_6': x__read_cgroup_v2_limit__mutmut_6, 
    'x__read_cgroup_v2_limit__mutmut_7': x__read_cgroup_v2_limit__mutmut_7, 
    'x__read_cgroup_v2_limit__mutmut_8': x__read_cgroup_v2_limit__mutmut_8, 
    'x__read_cgroup_v2_limit__mutmut_9': x__read_cgroup_v2_limit__mutmut_9, 
    'x__read_cgroup_v2_limit__mutmut_10': x__read_cgroup_v2_limit__mutmut_10, 
    'x__read_cgroup_v2_limit__mutmut_11': x__read_cgroup_v2_limit__mutmut_11, 
    'x__read_cgroup_v2_limit__mutmut_12': x__read_cgroup_v2_limit__mutmut_12, 
    'x__read_cgroup_v2_limit__mutmut_13': x__read_cgroup_v2_limit__mutmut_13, 
    'x__read_cgroup_v2_limit__mutmut_14': x__read_cgroup_v2_limit__mutmut_14, 
    'x__read_cgroup_v2_limit__mutmut_15': x__read_cgroup_v2_limit__mutmut_15, 
    'x__read_cgroup_v2_limit__mutmut_16': x__read_cgroup_v2_limit__mutmut_16, 
    'x__read_cgroup_v2_limit__mutmut_17': x__read_cgroup_v2_limit__mutmut_17, 
    'x__read_cgroup_v2_limit__mutmut_18': x__read_cgroup_v2_limit__mutmut_18, 
    'x__read_cgroup_v2_limit__mutmut_19': x__read_cgroup_v2_limit__mutmut_19, 
    'x__read_cgroup_v2_limit__mutmut_20': x__read_cgroup_v2_limit__mutmut_20, 
    'x__read_cgroup_v2_limit__mutmut_21': x__read_cgroup_v2_limit__mutmut_21, 
    'x__read_cgroup_v2_limit__mutmut_22': x__read_cgroup_v2_limit__mutmut_22, 
    'x__read_cgroup_v2_limit__mutmut_23': x__read_cgroup_v2_limit__mutmut_23, 
    'x__read_cgroup_v2_limit__mutmut_24': x__read_cgroup_v2_limit__mutmut_24, 
    'x__read_cgroup_v2_limit__mutmut_25': x__read_cgroup_v2_limit__mutmut_25, 
    'x__read_cgroup_v2_limit__mutmut_26': x__read_cgroup_v2_limit__mutmut_26, 
    'x__read_cgroup_v2_limit__mutmut_27': x__read_cgroup_v2_limit__mutmut_27, 
    'x__read_cgroup_v2_limit__mutmut_28': x__read_cgroup_v2_limit__mutmut_28, 
    'x__read_cgroup_v2_limit__mutmut_29': x__read_cgroup_v2_limit__mutmut_29, 
    'x__read_cgroup_v2_limit__mutmut_30': x__read_cgroup_v2_limit__mutmut_30, 
    'x__read_cgroup_v2_limit__mutmut_31': x__read_cgroup_v2_limit__mutmut_31, 
    'x__read_cgroup_v2_limit__mutmut_32': x__read_cgroup_v2_limit__mutmut_32, 
    'x__read_cgroup_v2_limit__mutmut_33': x__read_cgroup_v2_limit__mutmut_33, 
    'x__read_cgroup_v2_limit__mutmut_34': x__read_cgroup_v2_limit__mutmut_34, 
    'x__read_cgroup_v2_limit__mutmut_35': x__read_cgroup_v2_limit__mutmut_35, 
    'x__read_cgroup_v2_limit__mutmut_36': x__read_cgroup_v2_limit__mutmut_36, 
    'x__read_cgroup_v2_limit__mutmut_37': x__read_cgroup_v2_limit__mutmut_37, 
    'x__read_cgroup_v2_limit__mutmut_38': x__read_cgroup_v2_limit__mutmut_38, 
    'x__read_cgroup_v2_limit__mutmut_39': x__read_cgroup_v2_limit__mutmut_39, 
    'x__read_cgroup_v2_limit__mutmut_40': x__read_cgroup_v2_limit__mutmut_40, 
    'x__read_cgroup_v2_limit__mutmut_41': x__read_cgroup_v2_limit__mutmut_41, 
    'x__read_cgroup_v2_limit__mutmut_42': x__read_cgroup_v2_limit__mutmut_42, 
    'x__read_cgroup_v2_limit__mutmut_43': x__read_cgroup_v2_limit__mutmut_43, 
    'x__read_cgroup_v2_limit__mutmut_44': x__read_cgroup_v2_limit__mutmut_44, 
    'x__read_cgroup_v2_limit__mutmut_45': x__read_cgroup_v2_limit__mutmut_45, 
    'x__read_cgroup_v2_limit__mutmut_46': x__read_cgroup_v2_limit__mutmut_46, 
    'x__read_cgroup_v2_limit__mutmut_47': x__read_cgroup_v2_limit__mutmut_47, 
    'x__read_cgroup_v2_limit__mutmut_48': x__read_cgroup_v2_limit__mutmut_48, 
    'x__read_cgroup_v2_limit__mutmut_49': x__read_cgroup_v2_limit__mutmut_49, 
    'x__read_cgroup_v2_limit__mutmut_50': x__read_cgroup_v2_limit__mutmut_50, 
    'x__read_cgroup_v2_limit__mutmut_51': x__read_cgroup_v2_limit__mutmut_51
}

def _read_cgroup_v2_limit(*args, **kwargs):
    result = _mutmut_trampoline(x__read_cgroup_v2_limit__mutmut_orig, x__read_cgroup_v2_limit__mutmut_mutants, args, kwargs)
    return result 

_read_cgroup_v2_limit.__signature__ = _mutmut_signature(x__read_cgroup_v2_limit__mutmut_orig)
x__read_cgroup_v2_limit__mutmut_orig.__name__ = 'x__read_cgroup_v2_limit'


def x__get_cgroup_path__mutmut_orig() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_1() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open(None, 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_2() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', None) as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_3() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_4() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', ) as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_5() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('XX/proc/self/cgroupXX', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_6() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/PROC/SELF/CGROUP', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_7() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'XXrXX') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_8() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'R') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_9() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = None
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_10() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_11() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    break

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_12() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = None
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_13() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(None)
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_14() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split('XX:XX')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_15() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) > 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_16() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 4:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_17() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' or parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_18() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[1] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_19() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] != '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_20() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == 'XX0XX' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_21() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[2] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_22() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] != '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_23() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == 'XXXX':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_24() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[3]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_25() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'XXmemoryXX' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_26() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'MEMORY' in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_27() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' not in parts[1]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_28() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[2]:
                        return parts[2]
    except (IOError, ValueError):
        pass

    return None


def x__get_cgroup_path__mutmut_29() -> Optional[str]:
    """
    Get the cgroup path for the current process from /proc/self/cgroup.

    Returns:
        Cgroup path for the current process, or None if not found

    Rationale:
        In modern container environments, cgroup paths can be hierarchical.
        We need to read /proc/self/cgroup to find where our process is
        actually located in the cgroup hierarchy.

    Example /proc/self/cgroup formats:
        cgroup v2: 0::/docker/abc123...
        cgroup v1: 3:memory:/docker/abc123...
    """
    try:
        with open('/proc/self/cgroup', 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split(':')
                if len(parts) >= 3:
                    # cgroup v2 format: 0::/path
                    if parts[0] == '0' and parts[1] == '':
                        return parts[2]
                    # cgroup v1 format: N:controller:/path
                    elif 'memory' in parts[1]:
                        return parts[3]
    except (IOError, ValueError):
        pass

    return None

x__get_cgroup_path__mutmut_mutants : ClassVar[MutantDict] = {
'x__get_cgroup_path__mutmut_1': x__get_cgroup_path__mutmut_1, 
    'x__get_cgroup_path__mutmut_2': x__get_cgroup_path__mutmut_2, 
    'x__get_cgroup_path__mutmut_3': x__get_cgroup_path__mutmut_3, 
    'x__get_cgroup_path__mutmut_4': x__get_cgroup_path__mutmut_4, 
    'x__get_cgroup_path__mutmut_5': x__get_cgroup_path__mutmut_5, 
    'x__get_cgroup_path__mutmut_6': x__get_cgroup_path__mutmut_6, 
    'x__get_cgroup_path__mutmut_7': x__get_cgroup_path__mutmut_7, 
    'x__get_cgroup_path__mutmut_8': x__get_cgroup_path__mutmut_8, 
    'x__get_cgroup_path__mutmut_9': x__get_cgroup_path__mutmut_9, 
    'x__get_cgroup_path__mutmut_10': x__get_cgroup_path__mutmut_10, 
    'x__get_cgroup_path__mutmut_11': x__get_cgroup_path__mutmut_11, 
    'x__get_cgroup_path__mutmut_12': x__get_cgroup_path__mutmut_12, 
    'x__get_cgroup_path__mutmut_13': x__get_cgroup_path__mutmut_13, 
    'x__get_cgroup_path__mutmut_14': x__get_cgroup_path__mutmut_14, 
    'x__get_cgroup_path__mutmut_15': x__get_cgroup_path__mutmut_15, 
    'x__get_cgroup_path__mutmut_16': x__get_cgroup_path__mutmut_16, 
    'x__get_cgroup_path__mutmut_17': x__get_cgroup_path__mutmut_17, 
    'x__get_cgroup_path__mutmut_18': x__get_cgroup_path__mutmut_18, 
    'x__get_cgroup_path__mutmut_19': x__get_cgroup_path__mutmut_19, 
    'x__get_cgroup_path__mutmut_20': x__get_cgroup_path__mutmut_20, 
    'x__get_cgroup_path__mutmut_21': x__get_cgroup_path__mutmut_21, 
    'x__get_cgroup_path__mutmut_22': x__get_cgroup_path__mutmut_22, 
    'x__get_cgroup_path__mutmut_23': x__get_cgroup_path__mutmut_23, 
    'x__get_cgroup_path__mutmut_24': x__get_cgroup_path__mutmut_24, 
    'x__get_cgroup_path__mutmut_25': x__get_cgroup_path__mutmut_25, 
    'x__get_cgroup_path__mutmut_26': x__get_cgroup_path__mutmut_26, 
    'x__get_cgroup_path__mutmut_27': x__get_cgroup_path__mutmut_27, 
    'x__get_cgroup_path__mutmut_28': x__get_cgroup_path__mutmut_28, 
    'x__get_cgroup_path__mutmut_29': x__get_cgroup_path__mutmut_29
}

def _get_cgroup_path(*args, **kwargs):
    result = _mutmut_trampoline(x__get_cgroup_path__mutmut_orig, x__get_cgroup_path__mutmut_mutants, args, kwargs)
    return result 

_get_cgroup_path.__signature__ = _mutmut_signature(x__get_cgroup_path__mutmut_orig)
x__get_cgroup_path__mutmut_orig.__name__ = 'x__get_cgroup_path'


def x__read_cgroup_memory_limit__mutmut_orig() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_1() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = None
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_2() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith(None):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_3() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('XX/XX'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_4() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = None  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_5() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[2:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_6() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = None
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_7() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join(None, cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_8() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", None)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_9() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join(cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_10() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", )
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_11() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("XX/sys/fs/cgroupXX", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_12() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/SYS/FS/CGROUP", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_13() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(None):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_14() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = None
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_15() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(None)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_16() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_17() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = None
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_18() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit(None)
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_19() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("XX/sys/fs/cgroupXX")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_20() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/SYS/FS/CGROUP")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_21() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_22() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = None
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_23() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "XX/sys/fs/cgroup/memory/memory.limit_in_bytesXX"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_24() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/SYS/FS/CGROUP/MEMORY/MEMORY.LIMIT_IN_BYTES"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_25() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(None):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_26() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(None, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_27() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, None) as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_28() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open('r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_29() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, ) as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_30() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'XXrXX') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_31() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'R') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_32() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = None
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_33() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(None)
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_34() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value <= (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_35() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 >> 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_36() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (2 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_37() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 63):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_38() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith(None):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_39() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('XX/XX'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_40() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = None

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_41() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[2:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_42() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = None
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_43() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join(None, cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_44() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", None, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_45() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, None)
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_46() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join(cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_47() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_48() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, )
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_49() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("XX/sys/fs/cgroup/memoryXX", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_50() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/SYS/FS/CGROUP/MEMORY", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_51() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "XXmemory.limit_in_bytesXX")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_52() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "MEMORY.LIMIT_IN_BYTES")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_53() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(None):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_54() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(None, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_55() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, None) as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_56() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open('r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_57() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, ) as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_58() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'XXrXX') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_59() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'R') as f:
                    value = int(f.read().strip())
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_60() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = None
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_61() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(None)
                    if value < (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_62() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value <= (1 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_63() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 >> 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_64() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (2 << 62):
                        return value
            except (IOError, ValueError):
                pass

    return None


def x__read_cgroup_memory_limit__mutmut_65() -> Optional[int]:
    """
    Read memory limit from cgroup (Docker/container environments).

    Returns:
        Memory limit in bytes, or None if not in a container or can't read

    Rationale:
        Docker and other containers use cgroups to limit resources.
        Without this check, we'd see the host's total memory and
        potentially spawn too many workers, causing OOM kills.

    Enhanced Detection (Iteration 69):
        - Supports cgroup v2 unified hierarchy with hierarchical paths
        - Respects both memory.max (hard) and memory.high (soft) limits
        - Properly handles /proc/self/cgroup path resolution
        - Falls back gracefully through multiple strategies

    Detection Strategy:
        1. Try cgroup v2 with process-specific path (most accurate)
        2. Try cgroup v2 at root (simple containers)
        3. Try cgroup v1 (legacy systems)
    """
    # Strategy 1: cgroup v2 with process-specific path
    # This handles hierarchical cgroup paths in modern containers
    cgroup_path = _get_cgroup_path()
    if cgroup_path:
        # Try to read from the process-specific cgroup path
        # Handle both absolute paths and relative paths
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]  # Remove leading slash

        full_path = os.path.join("/sys/fs/cgroup", cgroup_path)
        if os.path.exists(full_path):
            limit = _read_cgroup_v2_limit(full_path)
            if limit is not None:
                return limit

    # Strategy 2: cgroup v2 at root (simple containers like Docker with unified hierarchy)
    limit = _read_cgroup_v2_limit("/sys/fs/cgroup")
    if limit is not None:
        return limit

    # Strategy 3: cgroup v1 (legacy systems)
    cgroup_v1_path = "/sys/fs/cgroup/memory/memory.limit_in_bytes"
    if os.path.exists(cgroup_v1_path):
        try:
            with open(cgroup_v1_path, 'r') as f:
                value = int(f.read().strip())
                # Very large values (near max int64) indicate no limit
                if value < (1 << 62):
                    return value
        except (IOError, ValueError):
            pass

    # Strategy 4: cgroup v1 with process-specific path
    if cgroup_path:
        if cgroup_path.startswith('/'):
            cgroup_path = cgroup_path[1:]

        full_path = os.path.join("/sys/fs/cgroup/memory", cgroup_path, "memory.limit_in_bytes")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r') as f:
                    value = int(f.read().strip())
                    if value < (1 << 63):
                        return value
            except (IOError, ValueError):
                pass

    return None

x__read_cgroup_memory_limit__mutmut_mutants : ClassVar[MutantDict] = {
'x__read_cgroup_memory_limit__mutmut_1': x__read_cgroup_memory_limit__mutmut_1, 
    'x__read_cgroup_memory_limit__mutmut_2': x__read_cgroup_memory_limit__mutmut_2, 
    'x__read_cgroup_memory_limit__mutmut_3': x__read_cgroup_memory_limit__mutmut_3, 
    'x__read_cgroup_memory_limit__mutmut_4': x__read_cgroup_memory_limit__mutmut_4, 
    'x__read_cgroup_memory_limit__mutmut_5': x__read_cgroup_memory_limit__mutmut_5, 
    'x__read_cgroup_memory_limit__mutmut_6': x__read_cgroup_memory_limit__mutmut_6, 
    'x__read_cgroup_memory_limit__mutmut_7': x__read_cgroup_memory_limit__mutmut_7, 
    'x__read_cgroup_memory_limit__mutmut_8': x__read_cgroup_memory_limit__mutmut_8, 
    'x__read_cgroup_memory_limit__mutmut_9': x__read_cgroup_memory_limit__mutmut_9, 
    'x__read_cgroup_memory_limit__mutmut_10': x__read_cgroup_memory_limit__mutmut_10, 
    'x__read_cgroup_memory_limit__mutmut_11': x__read_cgroup_memory_limit__mutmut_11, 
    'x__read_cgroup_memory_limit__mutmut_12': x__read_cgroup_memory_limit__mutmut_12, 
    'x__read_cgroup_memory_limit__mutmut_13': x__read_cgroup_memory_limit__mutmut_13, 
    'x__read_cgroup_memory_limit__mutmut_14': x__read_cgroup_memory_limit__mutmut_14, 
    'x__read_cgroup_memory_limit__mutmut_15': x__read_cgroup_memory_limit__mutmut_15, 
    'x__read_cgroup_memory_limit__mutmut_16': x__read_cgroup_memory_limit__mutmut_16, 
    'x__read_cgroup_memory_limit__mutmut_17': x__read_cgroup_memory_limit__mutmut_17, 
    'x__read_cgroup_memory_limit__mutmut_18': x__read_cgroup_memory_limit__mutmut_18, 
    'x__read_cgroup_memory_limit__mutmut_19': x__read_cgroup_memory_limit__mutmut_19, 
    'x__read_cgroup_memory_limit__mutmut_20': x__read_cgroup_memory_limit__mutmut_20, 
    'x__read_cgroup_memory_limit__mutmut_21': x__read_cgroup_memory_limit__mutmut_21, 
    'x__read_cgroup_memory_limit__mutmut_22': x__read_cgroup_memory_limit__mutmut_22, 
    'x__read_cgroup_memory_limit__mutmut_23': x__read_cgroup_memory_limit__mutmut_23, 
    'x__read_cgroup_memory_limit__mutmut_24': x__read_cgroup_memory_limit__mutmut_24, 
    'x__read_cgroup_memory_limit__mutmut_25': x__read_cgroup_memory_limit__mutmut_25, 
    'x__read_cgroup_memory_limit__mutmut_26': x__read_cgroup_memory_limit__mutmut_26, 
    'x__read_cgroup_memory_limit__mutmut_27': x__read_cgroup_memory_limit__mutmut_27, 
    'x__read_cgroup_memory_limit__mutmut_28': x__read_cgroup_memory_limit__mutmut_28, 
    'x__read_cgroup_memory_limit__mutmut_29': x__read_cgroup_memory_limit__mutmut_29, 
    'x__read_cgroup_memory_limit__mutmut_30': x__read_cgroup_memory_limit__mutmut_30, 
    'x__read_cgroup_memory_limit__mutmut_31': x__read_cgroup_memory_limit__mutmut_31, 
    'x__read_cgroup_memory_limit__mutmut_32': x__read_cgroup_memory_limit__mutmut_32, 
    'x__read_cgroup_memory_limit__mutmut_33': x__read_cgroup_memory_limit__mutmut_33, 
    'x__read_cgroup_memory_limit__mutmut_34': x__read_cgroup_memory_limit__mutmut_34, 
    'x__read_cgroup_memory_limit__mutmut_35': x__read_cgroup_memory_limit__mutmut_35, 
    'x__read_cgroup_memory_limit__mutmut_36': x__read_cgroup_memory_limit__mutmut_36, 
    'x__read_cgroup_memory_limit__mutmut_37': x__read_cgroup_memory_limit__mutmut_37, 
    'x__read_cgroup_memory_limit__mutmut_38': x__read_cgroup_memory_limit__mutmut_38, 
    'x__read_cgroup_memory_limit__mutmut_39': x__read_cgroup_memory_limit__mutmut_39, 
    'x__read_cgroup_memory_limit__mutmut_40': x__read_cgroup_memory_limit__mutmut_40, 
    'x__read_cgroup_memory_limit__mutmut_41': x__read_cgroup_memory_limit__mutmut_41, 
    'x__read_cgroup_memory_limit__mutmut_42': x__read_cgroup_memory_limit__mutmut_42, 
    'x__read_cgroup_memory_limit__mutmut_43': x__read_cgroup_memory_limit__mutmut_43, 
    'x__read_cgroup_memory_limit__mutmut_44': x__read_cgroup_memory_limit__mutmut_44, 
    'x__read_cgroup_memory_limit__mutmut_45': x__read_cgroup_memory_limit__mutmut_45, 
    'x__read_cgroup_memory_limit__mutmut_46': x__read_cgroup_memory_limit__mutmut_46, 
    'x__read_cgroup_memory_limit__mutmut_47': x__read_cgroup_memory_limit__mutmut_47, 
    'x__read_cgroup_memory_limit__mutmut_48': x__read_cgroup_memory_limit__mutmut_48, 
    'x__read_cgroup_memory_limit__mutmut_49': x__read_cgroup_memory_limit__mutmut_49, 
    'x__read_cgroup_memory_limit__mutmut_50': x__read_cgroup_memory_limit__mutmut_50, 
    'x__read_cgroup_memory_limit__mutmut_51': x__read_cgroup_memory_limit__mutmut_51, 
    'x__read_cgroup_memory_limit__mutmut_52': x__read_cgroup_memory_limit__mutmut_52, 
    'x__read_cgroup_memory_limit__mutmut_53': x__read_cgroup_memory_limit__mutmut_53, 
    'x__read_cgroup_memory_limit__mutmut_54': x__read_cgroup_memory_limit__mutmut_54, 
    'x__read_cgroup_memory_limit__mutmut_55': x__read_cgroup_memory_limit__mutmut_55, 
    'x__read_cgroup_memory_limit__mutmut_56': x__read_cgroup_memory_limit__mutmut_56, 
    'x__read_cgroup_memory_limit__mutmut_57': x__read_cgroup_memory_limit__mutmut_57, 
    'x__read_cgroup_memory_limit__mutmut_58': x__read_cgroup_memory_limit__mutmut_58, 
    'x__read_cgroup_memory_limit__mutmut_59': x__read_cgroup_memory_limit__mutmut_59, 
    'x__read_cgroup_memory_limit__mutmut_60': x__read_cgroup_memory_limit__mutmut_60, 
    'x__read_cgroup_memory_limit__mutmut_61': x__read_cgroup_memory_limit__mutmut_61, 
    'x__read_cgroup_memory_limit__mutmut_62': x__read_cgroup_memory_limit__mutmut_62, 
    'x__read_cgroup_memory_limit__mutmut_63': x__read_cgroup_memory_limit__mutmut_63, 
    'x__read_cgroup_memory_limit__mutmut_64': x__read_cgroup_memory_limit__mutmut_64, 
    'x__read_cgroup_memory_limit__mutmut_65': x__read_cgroup_memory_limit__mutmut_65
}

def _read_cgroup_memory_limit(*args, **kwargs):
    result = _mutmut_trampoline(x__read_cgroup_memory_limit__mutmut_orig, x__read_cgroup_memory_limit__mutmut_mutants, args, kwargs)
    return result 

_read_cgroup_memory_limit.__signature__ = _mutmut_signature(x__read_cgroup_memory_limit__mutmut_orig)
x__read_cgroup_memory_limit__mutmut_orig.__name__ = 'x__read_cgroup_memory_limit'


def x_get_available_memory__mutmut_orig() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_1() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = None

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_2() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None or (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_3() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None or _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_4() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_5() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_6() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time + _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_7() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) <= MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_8() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None or (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_9() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None or _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_10() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_11() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_12() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time + _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_13() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) <= MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_14() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = None

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_15() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = ""

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_16() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = None
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_17() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = None

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_18() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_19() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = None
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_20() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(None, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_21() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, None)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_22() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_23() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, )
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_24() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = None
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_25() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_26() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = None
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_27() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = None

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_28() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 / 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_29() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 / 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_30() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1025 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_31() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1025 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_32() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1025

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_33() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = None
        _memory_cache_timestamp = current_time

        return available_memory


def x_get_available_memory__mutmut_34() -> int:
    """
    Get available system memory in bytes, respecting container limits.

    The available memory is cached with a short TTL (Time-To-Live) to
    eliminate redundant system calls while still reflecting memory changes.
    Thread-safe: Uses lock to prevent concurrent detection.

    Returns:
        Available memory in bytes. Returns a conservative default if
        detection fails.

    Container Handling:
        Checks for Docker/cgroup memory limits before falling back to
        system memory. This prevents OOM kills in containerized environments.

    Fallback Strategy:
        1. Try cgroup limits (Docker/containers)
        2. Try psutil for system memory
        3. Return 1GB conservative default

    Performance:
        Cached with 1-second TTL to eliminate redundant file I/O and system
        calls within a single optimization session. The short TTL ensures we
        still respect memory changes that may occur during program execution.
        This is especially beneficial when multiple optimizations occur in
        rapid succession (e.g., batch processing, validation workflows).
    """
    global _CACHED_AVAILABLE_MEMORY, _memory_cache_timestamp

    current_time = time.perf_counter()

    # Quick check without lock (optimization for common case)
    if (_CACHED_AVAILABLE_MEMORY is not None and
        _memory_cache_timestamp is not None and
        (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
        return _CACHED_AVAILABLE_MEMORY

    # Acquire lock for detection
    with _memory_cache_lock:
        # Double-check after acquiring lock (another thread may have detected)
        if (_CACHED_AVAILABLE_MEMORY is not None and
            _memory_cache_timestamp is not None and
            (current_time - _memory_cache_timestamp) < MEMORY_CACHE_TTL):
            return _CACHED_AVAILABLE_MEMORY

        # Perform detection (only one thread reaches here)
        # First, check for container memory limits
        cgroup_limit = _read_cgroup_memory_limit()

        available_memory = None

        if HAS_PSUTIL:
            vm = psutil.virtual_memory()
            system_available = vm.available

            # If we're in a container, respect the lower limit
            if cgroup_limit is not None:
                available_memory = min(cgroup_limit, system_available)
            else:
                available_memory = system_available
        elif cgroup_limit is not None:
            # No psutil, but we have cgroup limit
            available_memory = cgroup_limit
        else:
            # Return a conservative estimate if detection fails (1GB)
            # Better to underestimate than cause OOM
            available_memory = 1024 * 1024 * 1024

        # Cache the result with timestamp
        _CACHED_AVAILABLE_MEMORY = available_memory
        _memory_cache_timestamp = None

        return available_memory

x_get_available_memory__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_available_memory__mutmut_1': x_get_available_memory__mutmut_1, 
    'x_get_available_memory__mutmut_2': x_get_available_memory__mutmut_2, 
    'x_get_available_memory__mutmut_3': x_get_available_memory__mutmut_3, 
    'x_get_available_memory__mutmut_4': x_get_available_memory__mutmut_4, 
    'x_get_available_memory__mutmut_5': x_get_available_memory__mutmut_5, 
    'x_get_available_memory__mutmut_6': x_get_available_memory__mutmut_6, 
    'x_get_available_memory__mutmut_7': x_get_available_memory__mutmut_7, 
    'x_get_available_memory__mutmut_8': x_get_available_memory__mutmut_8, 
    'x_get_available_memory__mutmut_9': x_get_available_memory__mutmut_9, 
    'x_get_available_memory__mutmut_10': x_get_available_memory__mutmut_10, 
    'x_get_available_memory__mutmut_11': x_get_available_memory__mutmut_11, 
    'x_get_available_memory__mutmut_12': x_get_available_memory__mutmut_12, 
    'x_get_available_memory__mutmut_13': x_get_available_memory__mutmut_13, 
    'x_get_available_memory__mutmut_14': x_get_available_memory__mutmut_14, 
    'x_get_available_memory__mutmut_15': x_get_available_memory__mutmut_15, 
    'x_get_available_memory__mutmut_16': x_get_available_memory__mutmut_16, 
    'x_get_available_memory__mutmut_17': x_get_available_memory__mutmut_17, 
    'x_get_available_memory__mutmut_18': x_get_available_memory__mutmut_18, 
    'x_get_available_memory__mutmut_19': x_get_available_memory__mutmut_19, 
    'x_get_available_memory__mutmut_20': x_get_available_memory__mutmut_20, 
    'x_get_available_memory__mutmut_21': x_get_available_memory__mutmut_21, 
    'x_get_available_memory__mutmut_22': x_get_available_memory__mutmut_22, 
    'x_get_available_memory__mutmut_23': x_get_available_memory__mutmut_23, 
    'x_get_available_memory__mutmut_24': x_get_available_memory__mutmut_24, 
    'x_get_available_memory__mutmut_25': x_get_available_memory__mutmut_25, 
    'x_get_available_memory__mutmut_26': x_get_available_memory__mutmut_26, 
    'x_get_available_memory__mutmut_27': x_get_available_memory__mutmut_27, 
    'x_get_available_memory__mutmut_28': x_get_available_memory__mutmut_28, 
    'x_get_available_memory__mutmut_29': x_get_available_memory__mutmut_29, 
    'x_get_available_memory__mutmut_30': x_get_available_memory__mutmut_30, 
    'x_get_available_memory__mutmut_31': x_get_available_memory__mutmut_31, 
    'x_get_available_memory__mutmut_32': x_get_available_memory__mutmut_32, 
    'x_get_available_memory__mutmut_33': x_get_available_memory__mutmut_33, 
    'x_get_available_memory__mutmut_34': x_get_available_memory__mutmut_34
}

def get_available_memory(*args, **kwargs):
    result = _mutmut_trampoline(x_get_available_memory__mutmut_orig, x_get_available_memory__mutmut_mutants, args, kwargs)
    return result 

get_available_memory.__signature__ = _mutmut_signature(x_get_available_memory__mutmut_orig)
x_get_available_memory__mutmut_orig.__name__ = 'x_get_available_memory'


def x_get_swap_usage__mutmut_orig() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if not HAS_PSUTIL:
        return 0.0, 0, 0

    try:
        swap = psutil.swap_memory()
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0, 0, 0


def x_get_swap_usage__mutmut_1() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if HAS_PSUTIL:
        return 0.0, 0, 0

    try:
        swap = psutil.swap_memory()
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0, 0, 0


def x_get_swap_usage__mutmut_2() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if not HAS_PSUTIL:
        return 1.0, 0, 0

    try:
        swap = psutil.swap_memory()
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0, 0, 0


def x_get_swap_usage__mutmut_3() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if not HAS_PSUTIL:
        return 0.0, 1, 0

    try:
        swap = psutil.swap_memory()
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0, 0, 0


def x_get_swap_usage__mutmut_4() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if not HAS_PSUTIL:
        return 0.0, 0, 1

    try:
        swap = psutil.swap_memory()
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0, 0, 0


def x_get_swap_usage__mutmut_5() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if not HAS_PSUTIL:
        return 0.0, 0, 0

    try:
        swap = None
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0, 0, 0


def x_get_swap_usage__mutmut_6() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if not HAS_PSUTIL:
        return 0.0, 0, 0

    try:
        swap = psutil.swap_memory()
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 1.0, 0, 0


def x_get_swap_usage__mutmut_7() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if not HAS_PSUTIL:
        return 0.0, 0, 0

    try:
        swap = psutil.swap_memory()
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0, 1, 0


def x_get_swap_usage__mutmut_8() -> Tuple[float, int, int]:
    """
    Get current swap memory usage information.

    Returns:
        Tuple of (swap_percent, swap_used_bytes, swap_total_bytes) where:
        - swap_percent: Percentage of swap being used (0-100)
        - swap_used_bytes: Amount of swap currently used in bytes
        - swap_total_bytes: Total swap space available in bytes

        Returns (0.0, 0, 0) if psutil is not available or swap detection fails.

    Rationale:
        When a system is actively using swap, it indicates memory pressure.
        Spawning additional workers in this state can cause severe performance
        degradation due to disk I/O thrashing as the kernel swaps memory pages
        to/from disk.

    Note:
        Some systems (like containers) may have no swap configured, which is
        normal and not an error condition.
    """
    if not HAS_PSUTIL:
        return 0.0, 0, 0

    try:
        swap = psutil.swap_memory()
        return swap.percent, swap.used, swap.total
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0, 0, 1

x_get_swap_usage__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_swap_usage__mutmut_1': x_get_swap_usage__mutmut_1, 
    'x_get_swap_usage__mutmut_2': x_get_swap_usage__mutmut_2, 
    'x_get_swap_usage__mutmut_3': x_get_swap_usage__mutmut_3, 
    'x_get_swap_usage__mutmut_4': x_get_swap_usage__mutmut_4, 
    'x_get_swap_usage__mutmut_5': x_get_swap_usage__mutmut_5, 
    'x_get_swap_usage__mutmut_6': x_get_swap_usage__mutmut_6, 
    'x_get_swap_usage__mutmut_7': x_get_swap_usage__mutmut_7, 
    'x_get_swap_usage__mutmut_8': x_get_swap_usage__mutmut_8
}

def get_swap_usage(*args, **kwargs):
    result = _mutmut_trampoline(x_get_swap_usage__mutmut_orig, x_get_swap_usage__mutmut_mutants, args, kwargs)
    return result 

get_swap_usage.__signature__ = _mutmut_signature(x_get_swap_usage__mutmut_orig)
x_get_swap_usage__mutmut_orig.__name__ = 'x_get_swap_usage'


def x_calculate_max_workers__mutmut_orig(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_1(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = None

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_2(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = None

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_3(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(None)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_4(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram / 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_5(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 1.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_6(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram >= 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_7(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 1:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_8(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = None
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_9(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(None, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_10(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, None)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_11(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_12(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, )
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_13(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(2, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_14(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram / estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_15(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = None

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_16(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = None

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_17(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(None, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_18(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, None)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_19(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_20(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, )

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_21(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = None

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_22(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent >= 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_23(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 51.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_24(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = None
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_25(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(None, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_26(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, None)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_27(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_28(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, )
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_29(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(2, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_30(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers / 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_31(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 3)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_32(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent >= 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_33(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 11.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_34(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = None
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_35(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(None, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_36(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, None)
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_37(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_38(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, )
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_39(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(2, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_40(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(None))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_41(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers / 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_42(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 1.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = base_workers

    return adjusted_workers


def x_calculate_max_workers__mutmut_43(physical_cores: int, estimated_job_ram: int) -> int:
    """
    Calculate maximum number of workers based on memory constraints.

    Enhanced in Iteration 70 to account for swap usage. When the system
    is actively swapping, worker count is reduced to prevent disk thrashing.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes

    Returns:
        Maximum number of workers, potentially reduced if system is swapping

    Swap-Aware Logic:
        - If swap usage < 10%: No adjustment (normal operation)
        - If swap usage 10-50%: Reduce workers by 25% (moderate pressure)
        - If swap usage > 50%: Reduce workers by 50% (severe pressure)

        This prevents spawning too many workers when the system is already
        under memory pressure, which would cause severe performance degradation.
    """
    available_ram = get_available_memory()

    # Leave some headroom (20%) for the system
    usable_ram = int(available_ram * 0.8)

    # Calculate memory-based limit
    if estimated_job_ram > 0:
        memory_limit = max(1, usable_ram // estimated_job_ram)
    else:
        memory_limit = physical_cores

    # Apply swap-aware adjustment
    base_workers = min(physical_cores, memory_limit)

    # Check swap usage
    swap_percent, _, _ = get_swap_usage()

    if swap_percent > 50.0:
        # Severe swap usage - reduce workers by 50%
        adjusted_workers = max(1, base_workers // 2)
    elif swap_percent > 10.0:
        # Moderate swap usage - reduce workers by 25%
        adjusted_workers = max(1, int(base_workers * 0.75))
    else:
        # No significant swap usage - use full worker count
        adjusted_workers = None

    return adjusted_workers

x_calculate_max_workers__mutmut_mutants : ClassVar[MutantDict] = {
'x_calculate_max_workers__mutmut_1': x_calculate_max_workers__mutmut_1, 
    'x_calculate_max_workers__mutmut_2': x_calculate_max_workers__mutmut_2, 
    'x_calculate_max_workers__mutmut_3': x_calculate_max_workers__mutmut_3, 
    'x_calculate_max_workers__mutmut_4': x_calculate_max_workers__mutmut_4, 
    'x_calculate_max_workers__mutmut_5': x_calculate_max_workers__mutmut_5, 
    'x_calculate_max_workers__mutmut_6': x_calculate_max_workers__mutmut_6, 
    'x_calculate_max_workers__mutmut_7': x_calculate_max_workers__mutmut_7, 
    'x_calculate_max_workers__mutmut_8': x_calculate_max_workers__mutmut_8, 
    'x_calculate_max_workers__mutmut_9': x_calculate_max_workers__mutmut_9, 
    'x_calculate_max_workers__mutmut_10': x_calculate_max_workers__mutmut_10, 
    'x_calculate_max_workers__mutmut_11': x_calculate_max_workers__mutmut_11, 
    'x_calculate_max_workers__mutmut_12': x_calculate_max_workers__mutmut_12, 
    'x_calculate_max_workers__mutmut_13': x_calculate_max_workers__mutmut_13, 
    'x_calculate_max_workers__mutmut_14': x_calculate_max_workers__mutmut_14, 
    'x_calculate_max_workers__mutmut_15': x_calculate_max_workers__mutmut_15, 
    'x_calculate_max_workers__mutmut_16': x_calculate_max_workers__mutmut_16, 
    'x_calculate_max_workers__mutmut_17': x_calculate_max_workers__mutmut_17, 
    'x_calculate_max_workers__mutmut_18': x_calculate_max_workers__mutmut_18, 
    'x_calculate_max_workers__mutmut_19': x_calculate_max_workers__mutmut_19, 
    'x_calculate_max_workers__mutmut_20': x_calculate_max_workers__mutmut_20, 
    'x_calculate_max_workers__mutmut_21': x_calculate_max_workers__mutmut_21, 
    'x_calculate_max_workers__mutmut_22': x_calculate_max_workers__mutmut_22, 
    'x_calculate_max_workers__mutmut_23': x_calculate_max_workers__mutmut_23, 
    'x_calculate_max_workers__mutmut_24': x_calculate_max_workers__mutmut_24, 
    'x_calculate_max_workers__mutmut_25': x_calculate_max_workers__mutmut_25, 
    'x_calculate_max_workers__mutmut_26': x_calculate_max_workers__mutmut_26, 
    'x_calculate_max_workers__mutmut_27': x_calculate_max_workers__mutmut_27, 
    'x_calculate_max_workers__mutmut_28': x_calculate_max_workers__mutmut_28, 
    'x_calculate_max_workers__mutmut_29': x_calculate_max_workers__mutmut_29, 
    'x_calculate_max_workers__mutmut_30': x_calculate_max_workers__mutmut_30, 
    'x_calculate_max_workers__mutmut_31': x_calculate_max_workers__mutmut_31, 
    'x_calculate_max_workers__mutmut_32': x_calculate_max_workers__mutmut_32, 
    'x_calculate_max_workers__mutmut_33': x_calculate_max_workers__mutmut_33, 
    'x_calculate_max_workers__mutmut_34': x_calculate_max_workers__mutmut_34, 
    'x_calculate_max_workers__mutmut_35': x_calculate_max_workers__mutmut_35, 
    'x_calculate_max_workers__mutmut_36': x_calculate_max_workers__mutmut_36, 
    'x_calculate_max_workers__mutmut_37': x_calculate_max_workers__mutmut_37, 
    'x_calculate_max_workers__mutmut_38': x_calculate_max_workers__mutmut_38, 
    'x_calculate_max_workers__mutmut_39': x_calculate_max_workers__mutmut_39, 
    'x_calculate_max_workers__mutmut_40': x_calculate_max_workers__mutmut_40, 
    'x_calculate_max_workers__mutmut_41': x_calculate_max_workers__mutmut_41, 
    'x_calculate_max_workers__mutmut_42': x_calculate_max_workers__mutmut_42, 
    'x_calculate_max_workers__mutmut_43': x_calculate_max_workers__mutmut_43
}

def calculate_max_workers(*args, **kwargs):
    result = _mutmut_trampoline(x_calculate_max_workers__mutmut_orig, x_calculate_max_workers__mutmut_mutants, args, kwargs)
    return result 

calculate_max_workers.__signature__ = _mutmut_signature(x_calculate_max_workers__mutmut_orig)
x_calculate_max_workers__mutmut_orig.__name__ = 'x_calculate_max_workers'


def x_get_current_cpu_load__mutmut_orig(interval: float = 0.1) -> float:
    """
    Get current system-wide CPU load as a percentage.

    Args:
        interval: Time interval in seconds to measure CPU usage (default: 0.1s)
                 A longer interval provides more accurate measurements but adds latency.

    Returns:
        CPU usage percentage (0.0-100.0) averaged across all logical cores.
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Real-time CPU load helps detect if the system is already busy.
        When CPU load is high, spawning more workers may not improve performance
        and could lead to contention and context switching overhead.

    Note:
        This function is intentionally NOT cached because CPU load changes
        rapidly and we want fresh measurements for dynamic adjustment.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        # psutil.cpu_percent() with interval > 0 blocks and measures CPU usage
        # over that interval, providing a more accurate snapshot than interval=0
        cpu_percent = psutil.cpu_percent(interval=interval)
        return float(cpu_percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_current_cpu_load__mutmut_1(interval: float = 1.1) -> float:
    """
    Get current system-wide CPU load as a percentage.

    Args:
        interval: Time interval in seconds to measure CPU usage (default: 0.1s)
                 A longer interval provides more accurate measurements but adds latency.

    Returns:
        CPU usage percentage (0.0-100.0) averaged across all logical cores.
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Real-time CPU load helps detect if the system is already busy.
        When CPU load is high, spawning more workers may not improve performance
        and could lead to contention and context switching overhead.

    Note:
        This function is intentionally NOT cached because CPU load changes
        rapidly and we want fresh measurements for dynamic adjustment.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        # psutil.cpu_percent() with interval > 0 blocks and measures CPU usage
        # over that interval, providing a more accurate snapshot than interval=0
        cpu_percent = psutil.cpu_percent(interval=interval)
        return float(cpu_percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_current_cpu_load__mutmut_2(interval: float = 0.1) -> float:
    """
    Get current system-wide CPU load as a percentage.

    Args:
        interval: Time interval in seconds to measure CPU usage (default: 0.1s)
                 A longer interval provides more accurate measurements but adds latency.

    Returns:
        CPU usage percentage (0.0-100.0) averaged across all logical cores.
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Real-time CPU load helps detect if the system is already busy.
        When CPU load is high, spawning more workers may not improve performance
        and could lead to contention and context switching overhead.

    Note:
        This function is intentionally NOT cached because CPU load changes
        rapidly and we want fresh measurements for dynamic adjustment.
    """
    if HAS_PSUTIL:
        return 0.0

    try:
        # psutil.cpu_percent() with interval > 0 blocks and measures CPU usage
        # over that interval, providing a more accurate snapshot than interval=0
        cpu_percent = psutil.cpu_percent(interval=interval)
        return float(cpu_percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_current_cpu_load__mutmut_3(interval: float = 0.1) -> float:
    """
    Get current system-wide CPU load as a percentage.

    Args:
        interval: Time interval in seconds to measure CPU usage (default: 0.1s)
                 A longer interval provides more accurate measurements but adds latency.

    Returns:
        CPU usage percentage (0.0-100.0) averaged across all logical cores.
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Real-time CPU load helps detect if the system is already busy.
        When CPU load is high, spawning more workers may not improve performance
        and could lead to contention and context switching overhead.

    Note:
        This function is intentionally NOT cached because CPU load changes
        rapidly and we want fresh measurements for dynamic adjustment.
    """
    if not HAS_PSUTIL:
        return 1.0

    try:
        # psutil.cpu_percent() with interval > 0 blocks and measures CPU usage
        # over that interval, providing a more accurate snapshot than interval=0
        cpu_percent = psutil.cpu_percent(interval=interval)
        return float(cpu_percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_current_cpu_load__mutmut_4(interval: float = 0.1) -> float:
    """
    Get current system-wide CPU load as a percentage.

    Args:
        interval: Time interval in seconds to measure CPU usage (default: 0.1s)
                 A longer interval provides more accurate measurements but adds latency.

    Returns:
        CPU usage percentage (0.0-100.0) averaged across all logical cores.
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Real-time CPU load helps detect if the system is already busy.
        When CPU load is high, spawning more workers may not improve performance
        and could lead to contention and context switching overhead.

    Note:
        This function is intentionally NOT cached because CPU load changes
        rapidly and we want fresh measurements for dynamic adjustment.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        # psutil.cpu_percent() with interval > 0 blocks and measures CPU usage
        # over that interval, providing a more accurate snapshot than interval=0
        cpu_percent = None
        return float(cpu_percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_current_cpu_load__mutmut_5(interval: float = 0.1) -> float:
    """
    Get current system-wide CPU load as a percentage.

    Args:
        interval: Time interval in seconds to measure CPU usage (default: 0.1s)
                 A longer interval provides more accurate measurements but adds latency.

    Returns:
        CPU usage percentage (0.0-100.0) averaged across all logical cores.
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Real-time CPU load helps detect if the system is already busy.
        When CPU load is high, spawning more workers may not improve performance
        and could lead to contention and context switching overhead.

    Note:
        This function is intentionally NOT cached because CPU load changes
        rapidly and we want fresh measurements for dynamic adjustment.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        # psutil.cpu_percent() with interval > 0 blocks and measures CPU usage
        # over that interval, providing a more accurate snapshot than interval=0
        cpu_percent = psutil.cpu_percent(interval=None)
        return float(cpu_percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_current_cpu_load__mutmut_6(interval: float = 0.1) -> float:
    """
    Get current system-wide CPU load as a percentage.

    Args:
        interval: Time interval in seconds to measure CPU usage (default: 0.1s)
                 A longer interval provides more accurate measurements but adds latency.

    Returns:
        CPU usage percentage (0.0-100.0) averaged across all logical cores.
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Real-time CPU load helps detect if the system is already busy.
        When CPU load is high, spawning more workers may not improve performance
        and could lead to contention and context switching overhead.

    Note:
        This function is intentionally NOT cached because CPU load changes
        rapidly and we want fresh measurements for dynamic adjustment.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        # psutil.cpu_percent() with interval > 0 blocks and measures CPU usage
        # over that interval, providing a more accurate snapshot than interval=0
        cpu_percent = psutil.cpu_percent(interval=interval)
        return float(None)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_current_cpu_load__mutmut_7(interval: float = 0.1) -> float:
    """
    Get current system-wide CPU load as a percentage.

    Args:
        interval: Time interval in seconds to measure CPU usage (default: 0.1s)
                 A longer interval provides more accurate measurements but adds latency.

    Returns:
        CPU usage percentage (0.0-100.0) averaged across all logical cores.
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Real-time CPU load helps detect if the system is already busy.
        When CPU load is high, spawning more workers may not improve performance
        and could lead to contention and context switching overhead.

    Note:
        This function is intentionally NOT cached because CPU load changes
        rapidly and we want fresh measurements for dynamic adjustment.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        # psutil.cpu_percent() with interval > 0 blocks and measures CPU usage
        # over that interval, providing a more accurate snapshot than interval=0
        cpu_percent = psutil.cpu_percent(interval=interval)
        return float(cpu_percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 1.0

x_get_current_cpu_load__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_current_cpu_load__mutmut_1': x_get_current_cpu_load__mutmut_1, 
    'x_get_current_cpu_load__mutmut_2': x_get_current_cpu_load__mutmut_2, 
    'x_get_current_cpu_load__mutmut_3': x_get_current_cpu_load__mutmut_3, 
    'x_get_current_cpu_load__mutmut_4': x_get_current_cpu_load__mutmut_4, 
    'x_get_current_cpu_load__mutmut_5': x_get_current_cpu_load__mutmut_5, 
    'x_get_current_cpu_load__mutmut_6': x_get_current_cpu_load__mutmut_6, 
    'x_get_current_cpu_load__mutmut_7': x_get_current_cpu_load__mutmut_7
}

def get_current_cpu_load(*args, **kwargs):
    result = _mutmut_trampoline(x_get_current_cpu_load__mutmut_orig, x_get_current_cpu_load__mutmut_mutants, args, kwargs)
    return result 

get_current_cpu_load.__signature__ = _mutmut_signature(x_get_current_cpu_load__mutmut_orig)
x_get_current_cpu_load__mutmut_orig.__name__ = 'x_get_current_cpu_load'


def x_get_memory_pressure__mutmut_orig() -> float:
    """
    Get current memory pressure as a percentage of used memory.

    Returns:
        Memory usage percentage (0.0-100.0).
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Memory pressure indicates how much of the system's RAM is currently in use.
        High memory pressure means spawning more workers may cause OOM or swapping.
        This complements get_available_memory() by showing current usage trends.

    Note:
        This function is intentionally NOT cached because memory usage changes
        dynamically and we want fresh measurements for load-aware decisions.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        vm = psutil.virtual_memory()
        return float(vm.percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_memory_pressure__mutmut_1() -> float:
    """
    Get current memory pressure as a percentage of used memory.

    Returns:
        Memory usage percentage (0.0-100.0).
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Memory pressure indicates how much of the system's RAM is currently in use.
        High memory pressure means spawning more workers may cause OOM or swapping.
        This complements get_available_memory() by showing current usage trends.

    Note:
        This function is intentionally NOT cached because memory usage changes
        dynamically and we want fresh measurements for load-aware decisions.
    """
    if HAS_PSUTIL:
        return 0.0

    try:
        vm = psutil.virtual_memory()
        return float(vm.percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_memory_pressure__mutmut_2() -> float:
    """
    Get current memory pressure as a percentage of used memory.

    Returns:
        Memory usage percentage (0.0-100.0).
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Memory pressure indicates how much of the system's RAM is currently in use.
        High memory pressure means spawning more workers may cause OOM or swapping.
        This complements get_available_memory() by showing current usage trends.

    Note:
        This function is intentionally NOT cached because memory usage changes
        dynamically and we want fresh measurements for load-aware decisions.
    """
    if not HAS_PSUTIL:
        return 1.0

    try:
        vm = psutil.virtual_memory()
        return float(vm.percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_memory_pressure__mutmut_3() -> float:
    """
    Get current memory pressure as a percentage of used memory.

    Returns:
        Memory usage percentage (0.0-100.0).
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Memory pressure indicates how much of the system's RAM is currently in use.
        High memory pressure means spawning more workers may cause OOM or swapping.
        This complements get_available_memory() by showing current usage trends.

    Note:
        This function is intentionally NOT cached because memory usage changes
        dynamically and we want fresh measurements for load-aware decisions.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        vm = None
        return float(vm.percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_memory_pressure__mutmut_4() -> float:
    """
    Get current memory pressure as a percentage of used memory.

    Returns:
        Memory usage percentage (0.0-100.0).
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Memory pressure indicates how much of the system's RAM is currently in use.
        High memory pressure means spawning more workers may cause OOM or swapping.
        This complements get_available_memory() by showing current usage trends.

    Note:
        This function is intentionally NOT cached because memory usage changes
        dynamically and we want fresh measurements for load-aware decisions.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        vm = psutil.virtual_memory()
        return float(None)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 0.0


def x_get_memory_pressure__mutmut_5() -> float:
    """
    Get current memory pressure as a percentage of used memory.

    Returns:
        Memory usage percentage (0.0-100.0).
        Returns 0.0 if psutil is not available or measurement fails.

    Rationale:
        Memory pressure indicates how much of the system's RAM is currently in use.
        High memory pressure means spawning more workers may cause OOM or swapping.
        This complements get_available_memory() by showing current usage trends.

    Note:
        This function is intentionally NOT cached because memory usage changes
        dynamically and we want fresh measurements for load-aware decisions.
    """
    if not HAS_PSUTIL:
        return 0.0

    try:
        vm = psutil.virtual_memory()
        return float(vm.percent)
    except (AttributeError, OSError):
        # AttributeError: Method not available on this platform
        # OSError: System call failed
        return 1.0

x_get_memory_pressure__mutmut_mutants : ClassVar[MutantDict] = {
'x_get_memory_pressure__mutmut_1': x_get_memory_pressure__mutmut_1, 
    'x_get_memory_pressure__mutmut_2': x_get_memory_pressure__mutmut_2, 
    'x_get_memory_pressure__mutmut_3': x_get_memory_pressure__mutmut_3, 
    'x_get_memory_pressure__mutmut_4': x_get_memory_pressure__mutmut_4, 
    'x_get_memory_pressure__mutmut_5': x_get_memory_pressure__mutmut_5
}

def get_memory_pressure(*args, **kwargs):
    result = _mutmut_trampoline(x_get_memory_pressure__mutmut_orig, x_get_memory_pressure__mutmut_mutants, args, kwargs)
    return result 

get_memory_pressure.__signature__ = _mutmut_signature(x_get_memory_pressure__mutmut_orig)
x_get_memory_pressure__mutmut_orig.__name__ = 'x_get_memory_pressure'


def x_calculate_load_aware_workers__mutmut_orig(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_1(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 71.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_2(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 76.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_3(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = True
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_4(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = None

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_5(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(None, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_6(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, None)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_7(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_8(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, )

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_9(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = None
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_10(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = None

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_11(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu > cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_12(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold > 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_13(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 101.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_14(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = None
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_15(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(None, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_16(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, None)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_17(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_18(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, )
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_19(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(2, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_20(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers / 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_21(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 3)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_22(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = None
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_23(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(None, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_24(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, None)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_25(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_26(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, )
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_27(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(1.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_28(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 + current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_29(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 101.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_30(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = None

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_31(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent * (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_32(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 + cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_33(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (101.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_34(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = None
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_35(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(None, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_36(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, None)
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_37(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_38(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, )
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_39(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(2, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_40(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(None))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_41(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers / cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_42(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu > 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_43(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 91.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_44(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = None
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_45(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(None, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_46(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, None)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_47(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_48(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, )
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_49(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(2, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_50(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers / 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_51(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 3)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_52(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = None

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_53(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(None, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_54(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, None)

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_55(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_56(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, )

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_57(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(2, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_58(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(None))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_59(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers / 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_60(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 1.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_61(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = None
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_62(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = None

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_63(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory > memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_64(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold > 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_65(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 101.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_66(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = None
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_67(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(None, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_68(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, None)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_69(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_70(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, )
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_71(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(2, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_72(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers / 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_73(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 3)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_74(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = None
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_75(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(None, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_76(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, None)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_77(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_78(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, )
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_79(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(1.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_80(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 + current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_81(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 101.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_82(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = None

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_83(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent * (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_84(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 + memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_85(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (101.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_86(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = None
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_87(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(None, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_88(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, None)
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_89(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_90(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, )
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_91(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(2, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_92(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(None))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_93(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers / memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_94(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory > 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_95(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 91.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_96(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = None
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_97(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(None, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_98(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, None)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_99(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_100(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, )
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_101(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(2, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_102(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers / 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_103(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 3)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_104(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = None

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_105(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(None, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_106(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, None)

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_107(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_108(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, )

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_109(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(2, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_110(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(None))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_111(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers / 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_112(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 1.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_113(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = None

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_114(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(None, cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_115(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, None, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_116(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, None)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_117(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(cpu_adjusted_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_118(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, memory_adjusted_workers)

    return optimal_workers


def x_calculate_load_aware_workers__mutmut_119(
    physical_cores: int,
    estimated_job_ram: int,
    cpu_threshold: float = 70.0,
    memory_threshold: float = 75.0,
    aggressive_reduction: bool = False
) -> int:
    """
    Calculate optimal number of workers based on current system load.

    This function extends calculate_max_workers() by considering real-time
    system load (CPU and memory usage) in addition to hardware constraints.

    Args:
        physical_cores: Number of physical CPU cores
        estimated_job_ram: Estimated RAM usage per job in bytes
        cpu_threshold: CPU usage % above which to reduce workers (default: 70%)
        memory_threshold: Memory usage % above which to reduce workers (default: 75%)
        aggressive_reduction: If True, apply more aggressive reduction when system
                            is under load (default: False for backward compatibility)

    Returns:
        Optimal number of workers adjusted for current system load (minimum 1)

    Load-Aware Logic:
        1. Start with base calculation (physical cores + memory + swap constraints)
        2. Check current CPU load:
           - If CPU < threshold: No adjustment
           - If CPU >= threshold: Reduce workers proportionally to available capacity
        3. Check current memory pressure:
           - If memory < threshold: No adjustment
           - If memory >= threshold: Reduce workers to prevent OOM
        4. Apply the most conservative (lowest) worker count

    Examples:
        >>> # System: 8 cores, 50% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)  # 1GB per job
        8  # No reduction (below thresholds)

        >>> # System: 8 cores, 80% CPU load, 60% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high CPU (only 20% capacity remains)

        >>> # System: 8 cores, 50% CPU load, 85% memory usage
        >>> calculate_load_aware_workers(8, 1024*1024*1024)
        6  # Reduced due to high memory pressure

    Thread Safety:
        This function is thread-safe. It calls get_current_cpu_load() and
        get_memory_pressure() which are not cached and always return fresh data.
    """
    # Step 1: Calculate base worker count with existing constraints
    # (physical cores, memory limits, swap usage)
    base_workers = calculate_max_workers(physical_cores, estimated_job_ram)

    # Step 2: Check real-time CPU load
    current_cpu = get_current_cpu_load()
    cpu_adjusted_workers = base_workers

    if current_cpu >= cpu_threshold:
        # Prevent division by zero if cpu_threshold is 100.0
        if cpu_threshold >= 100.0:
            # If threshold is 100%, any load should reduce workers
            cpu_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available CPU capacity
            available_cpu_percent = max(0.0, 100.0 - current_cpu)
            cpu_capacity_ratio = available_cpu_percent / (100.0 - cpu_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                cpu_adjusted_workers = max(1, int(base_workers * cpu_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_cpu >= 90.0:
                    cpu_adjusted_workers = max(1, base_workers // 2)
                else:
                    cpu_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 3: Check real-time memory pressure
    current_memory = get_memory_pressure()
    memory_adjusted_workers = base_workers

    if current_memory >= memory_threshold:
        # Prevent division by zero if memory_threshold is 100.0
        if memory_threshold >= 100.0:
            # If threshold is 100%, any pressure should reduce workers
            memory_adjusted_workers = max(1, base_workers // 2)
        else:
            # Calculate available memory capacity
            available_memory_percent = max(0.0, 100.0 - current_memory)
            memory_capacity_ratio = available_memory_percent / (100.0 - memory_threshold)

            if aggressive_reduction:
                # More aggressive: scale linearly with available capacity
                memory_adjusted_workers = max(1, int(base_workers * memory_capacity_ratio))
            else:
                # Conservative: reduce by 25% if over threshold, 50% if very high (>90%)
                if current_memory >= 90.0:
                    memory_adjusted_workers = max(1, base_workers // 2)
                else:
                    memory_adjusted_workers = max(1, int(base_workers * 0.75))

    # Step 4: Apply the most conservative worker count
    # (take the minimum to ensure we don't overload any resource)
    optimal_workers = min(base_workers, cpu_adjusted_workers, )

    return optimal_workers

x_calculate_load_aware_workers__mutmut_mutants : ClassVar[MutantDict] = {
'x_calculate_load_aware_workers__mutmut_1': x_calculate_load_aware_workers__mutmut_1, 
    'x_calculate_load_aware_workers__mutmut_2': x_calculate_load_aware_workers__mutmut_2, 
    'x_calculate_load_aware_workers__mutmut_3': x_calculate_load_aware_workers__mutmut_3, 
    'x_calculate_load_aware_workers__mutmut_4': x_calculate_load_aware_workers__mutmut_4, 
    'x_calculate_load_aware_workers__mutmut_5': x_calculate_load_aware_workers__mutmut_5, 
    'x_calculate_load_aware_workers__mutmut_6': x_calculate_load_aware_workers__mutmut_6, 
    'x_calculate_load_aware_workers__mutmut_7': x_calculate_load_aware_workers__mutmut_7, 
    'x_calculate_load_aware_workers__mutmut_8': x_calculate_load_aware_workers__mutmut_8, 
    'x_calculate_load_aware_workers__mutmut_9': x_calculate_load_aware_workers__mutmut_9, 
    'x_calculate_load_aware_workers__mutmut_10': x_calculate_load_aware_workers__mutmut_10, 
    'x_calculate_load_aware_workers__mutmut_11': x_calculate_load_aware_workers__mutmut_11, 
    'x_calculate_load_aware_workers__mutmut_12': x_calculate_load_aware_workers__mutmut_12, 
    'x_calculate_load_aware_workers__mutmut_13': x_calculate_load_aware_workers__mutmut_13, 
    'x_calculate_load_aware_workers__mutmut_14': x_calculate_load_aware_workers__mutmut_14, 
    'x_calculate_load_aware_workers__mutmut_15': x_calculate_load_aware_workers__mutmut_15, 
    'x_calculate_load_aware_workers__mutmut_16': x_calculate_load_aware_workers__mutmut_16, 
    'x_calculate_load_aware_workers__mutmut_17': x_calculate_load_aware_workers__mutmut_17, 
    'x_calculate_load_aware_workers__mutmut_18': x_calculate_load_aware_workers__mutmut_18, 
    'x_calculate_load_aware_workers__mutmut_19': x_calculate_load_aware_workers__mutmut_19, 
    'x_calculate_load_aware_workers__mutmut_20': x_calculate_load_aware_workers__mutmut_20, 
    'x_calculate_load_aware_workers__mutmut_21': x_calculate_load_aware_workers__mutmut_21, 
    'x_calculate_load_aware_workers__mutmut_22': x_calculate_load_aware_workers__mutmut_22, 
    'x_calculate_load_aware_workers__mutmut_23': x_calculate_load_aware_workers__mutmut_23, 
    'x_calculate_load_aware_workers__mutmut_24': x_calculate_load_aware_workers__mutmut_24, 
    'x_calculate_load_aware_workers__mutmut_25': x_calculate_load_aware_workers__mutmut_25, 
    'x_calculate_load_aware_workers__mutmut_26': x_calculate_load_aware_workers__mutmut_26, 
    'x_calculate_load_aware_workers__mutmut_27': x_calculate_load_aware_workers__mutmut_27, 
    'x_calculate_load_aware_workers__mutmut_28': x_calculate_load_aware_workers__mutmut_28, 
    'x_calculate_load_aware_workers__mutmut_29': x_calculate_load_aware_workers__mutmut_29, 
    'x_calculate_load_aware_workers__mutmut_30': x_calculate_load_aware_workers__mutmut_30, 
    'x_calculate_load_aware_workers__mutmut_31': x_calculate_load_aware_workers__mutmut_31, 
    'x_calculate_load_aware_workers__mutmut_32': x_calculate_load_aware_workers__mutmut_32, 
    'x_calculate_load_aware_workers__mutmut_33': x_calculate_load_aware_workers__mutmut_33, 
    'x_calculate_load_aware_workers__mutmut_34': x_calculate_load_aware_workers__mutmut_34, 
    'x_calculate_load_aware_workers__mutmut_35': x_calculate_load_aware_workers__mutmut_35, 
    'x_calculate_load_aware_workers__mutmut_36': x_calculate_load_aware_workers__mutmut_36, 
    'x_calculate_load_aware_workers__mutmut_37': x_calculate_load_aware_workers__mutmut_37, 
    'x_calculate_load_aware_workers__mutmut_38': x_calculate_load_aware_workers__mutmut_38, 
    'x_calculate_load_aware_workers__mutmut_39': x_calculate_load_aware_workers__mutmut_39, 
    'x_calculate_load_aware_workers__mutmut_40': x_calculate_load_aware_workers__mutmut_40, 
    'x_calculate_load_aware_workers__mutmut_41': x_calculate_load_aware_workers__mutmut_41, 
    'x_calculate_load_aware_workers__mutmut_42': x_calculate_load_aware_workers__mutmut_42, 
    'x_calculate_load_aware_workers__mutmut_43': x_calculate_load_aware_workers__mutmut_43, 
    'x_calculate_load_aware_workers__mutmut_44': x_calculate_load_aware_workers__mutmut_44, 
    'x_calculate_load_aware_workers__mutmut_45': x_calculate_load_aware_workers__mutmut_45, 
    'x_calculate_load_aware_workers__mutmut_46': x_calculate_load_aware_workers__mutmut_46, 
    'x_calculate_load_aware_workers__mutmut_47': x_calculate_load_aware_workers__mutmut_47, 
    'x_calculate_load_aware_workers__mutmut_48': x_calculate_load_aware_workers__mutmut_48, 
    'x_calculate_load_aware_workers__mutmut_49': x_calculate_load_aware_workers__mutmut_49, 
    'x_calculate_load_aware_workers__mutmut_50': x_calculate_load_aware_workers__mutmut_50, 
    'x_calculate_load_aware_workers__mutmut_51': x_calculate_load_aware_workers__mutmut_51, 
    'x_calculate_load_aware_workers__mutmut_52': x_calculate_load_aware_workers__mutmut_52, 
    'x_calculate_load_aware_workers__mutmut_53': x_calculate_load_aware_workers__mutmut_53, 
    'x_calculate_load_aware_workers__mutmut_54': x_calculate_load_aware_workers__mutmut_54, 
    'x_calculate_load_aware_workers__mutmut_55': x_calculate_load_aware_workers__mutmut_55, 
    'x_calculate_load_aware_workers__mutmut_56': x_calculate_load_aware_workers__mutmut_56, 
    'x_calculate_load_aware_workers__mutmut_57': x_calculate_load_aware_workers__mutmut_57, 
    'x_calculate_load_aware_workers__mutmut_58': x_calculate_load_aware_workers__mutmut_58, 
    'x_calculate_load_aware_workers__mutmut_59': x_calculate_load_aware_workers__mutmut_59, 
    'x_calculate_load_aware_workers__mutmut_60': x_calculate_load_aware_workers__mutmut_60, 
    'x_calculate_load_aware_workers__mutmut_61': x_calculate_load_aware_workers__mutmut_61, 
    'x_calculate_load_aware_workers__mutmut_62': x_calculate_load_aware_workers__mutmut_62, 
    'x_calculate_load_aware_workers__mutmut_63': x_calculate_load_aware_workers__mutmut_63, 
    'x_calculate_load_aware_workers__mutmut_64': x_calculate_load_aware_workers__mutmut_64, 
    'x_calculate_load_aware_workers__mutmut_65': x_calculate_load_aware_workers__mutmut_65, 
    'x_calculate_load_aware_workers__mutmut_66': x_calculate_load_aware_workers__mutmut_66, 
    'x_calculate_load_aware_workers__mutmut_67': x_calculate_load_aware_workers__mutmut_67, 
    'x_calculate_load_aware_workers__mutmut_68': x_calculate_load_aware_workers__mutmut_68, 
    'x_calculate_load_aware_workers__mutmut_69': x_calculate_load_aware_workers__mutmut_69, 
    'x_calculate_load_aware_workers__mutmut_70': x_calculate_load_aware_workers__mutmut_70, 
    'x_calculate_load_aware_workers__mutmut_71': x_calculate_load_aware_workers__mutmut_71, 
    'x_calculate_load_aware_workers__mutmut_72': x_calculate_load_aware_workers__mutmut_72, 
    'x_calculate_load_aware_workers__mutmut_73': x_calculate_load_aware_workers__mutmut_73, 
    'x_calculate_load_aware_workers__mutmut_74': x_calculate_load_aware_workers__mutmut_74, 
    'x_calculate_load_aware_workers__mutmut_75': x_calculate_load_aware_workers__mutmut_75, 
    'x_calculate_load_aware_workers__mutmut_76': x_calculate_load_aware_workers__mutmut_76, 
    'x_calculate_load_aware_workers__mutmut_77': x_calculate_load_aware_workers__mutmut_77, 
    'x_calculate_load_aware_workers__mutmut_78': x_calculate_load_aware_workers__mutmut_78, 
    'x_calculate_load_aware_workers__mutmut_79': x_calculate_load_aware_workers__mutmut_79, 
    'x_calculate_load_aware_workers__mutmut_80': x_calculate_load_aware_workers__mutmut_80, 
    'x_calculate_load_aware_workers__mutmut_81': x_calculate_load_aware_workers__mutmut_81, 
    'x_calculate_load_aware_workers__mutmut_82': x_calculate_load_aware_workers__mutmut_82, 
    'x_calculate_load_aware_workers__mutmut_83': x_calculate_load_aware_workers__mutmut_83, 
    'x_calculate_load_aware_workers__mutmut_84': x_calculate_load_aware_workers__mutmut_84, 
    'x_calculate_load_aware_workers__mutmut_85': x_calculate_load_aware_workers__mutmut_85, 
    'x_calculate_load_aware_workers__mutmut_86': x_calculate_load_aware_workers__mutmut_86, 
    'x_calculate_load_aware_workers__mutmut_87': x_calculate_load_aware_workers__mutmut_87, 
    'x_calculate_load_aware_workers__mutmut_88': x_calculate_load_aware_workers__mutmut_88, 
    'x_calculate_load_aware_workers__mutmut_89': x_calculate_load_aware_workers__mutmut_89, 
    'x_calculate_load_aware_workers__mutmut_90': x_calculate_load_aware_workers__mutmut_90, 
    'x_calculate_load_aware_workers__mutmut_91': x_calculate_load_aware_workers__mutmut_91, 
    'x_calculate_load_aware_workers__mutmut_92': x_calculate_load_aware_workers__mutmut_92, 
    'x_calculate_load_aware_workers__mutmut_93': x_calculate_load_aware_workers__mutmut_93, 
    'x_calculate_load_aware_workers__mutmut_94': x_calculate_load_aware_workers__mutmut_94, 
    'x_calculate_load_aware_workers__mutmut_95': x_calculate_load_aware_workers__mutmut_95, 
    'x_calculate_load_aware_workers__mutmut_96': x_calculate_load_aware_workers__mutmut_96, 
    'x_calculate_load_aware_workers__mutmut_97': x_calculate_load_aware_workers__mutmut_97, 
    'x_calculate_load_aware_workers__mutmut_98': x_calculate_load_aware_workers__mutmut_98, 
    'x_calculate_load_aware_workers__mutmut_99': x_calculate_load_aware_workers__mutmut_99, 
    'x_calculate_load_aware_workers__mutmut_100': x_calculate_load_aware_workers__mutmut_100, 
    'x_calculate_load_aware_workers__mutmut_101': x_calculate_load_aware_workers__mutmut_101, 
    'x_calculate_load_aware_workers__mutmut_102': x_calculate_load_aware_workers__mutmut_102, 
    'x_calculate_load_aware_workers__mutmut_103': x_calculate_load_aware_workers__mutmut_103, 
    'x_calculate_load_aware_workers__mutmut_104': x_calculate_load_aware_workers__mutmut_104, 
    'x_calculate_load_aware_workers__mutmut_105': x_calculate_load_aware_workers__mutmut_105, 
    'x_calculate_load_aware_workers__mutmut_106': x_calculate_load_aware_workers__mutmut_106, 
    'x_calculate_load_aware_workers__mutmut_107': x_calculate_load_aware_workers__mutmut_107, 
    'x_calculate_load_aware_workers__mutmut_108': x_calculate_load_aware_workers__mutmut_108, 
    'x_calculate_load_aware_workers__mutmut_109': x_calculate_load_aware_workers__mutmut_109, 
    'x_calculate_load_aware_workers__mutmut_110': x_calculate_load_aware_workers__mutmut_110, 
    'x_calculate_load_aware_workers__mutmut_111': x_calculate_load_aware_workers__mutmut_111, 
    'x_calculate_load_aware_workers__mutmut_112': x_calculate_load_aware_workers__mutmut_112, 
    'x_calculate_load_aware_workers__mutmut_113': x_calculate_load_aware_workers__mutmut_113, 
    'x_calculate_load_aware_workers__mutmut_114': x_calculate_load_aware_workers__mutmut_114, 
    'x_calculate_load_aware_workers__mutmut_115': x_calculate_load_aware_workers__mutmut_115, 
    'x_calculate_load_aware_workers__mutmut_116': x_calculate_load_aware_workers__mutmut_116, 
    'x_calculate_load_aware_workers__mutmut_117': x_calculate_load_aware_workers__mutmut_117, 
    'x_calculate_load_aware_workers__mutmut_118': x_calculate_load_aware_workers__mutmut_118, 
    'x_calculate_load_aware_workers__mutmut_119': x_calculate_load_aware_workers__mutmut_119
}

def calculate_load_aware_workers(*args, **kwargs):
    result = _mutmut_trampoline(x_calculate_load_aware_workers__mutmut_orig, x_calculate_load_aware_workers__mutmut_mutants, args, kwargs)
    return result 

calculate_load_aware_workers.__signature__ = _mutmut_signature(x_calculate_load_aware_workers__mutmut_orig)
x_calculate_load_aware_workers__mutmut_orig.__name__ = 'x_calculate_load_aware_workers'


def get_system_info() -> Tuple[int, float, int]:
    """
    Get all relevant system information.

    Returns:
        Tuple of (physical_cores, spawn_cost, available_memory)
    """
    return (
        get_physical_cores(),
        get_spawn_cost(),
        get_available_memory()
    )
