{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Amorsize\n",
    "\n",
    "**Interactive Tutorial: Learn multiprocessing optimization in 10 minutes!**\n",
    "\n",
    "This notebook demonstrates how Amorsize automatically finds optimal `n_jobs` and `chunksize` parameters for Python multiprocessing, preventing \"negative scaling\" where parallelism makes code slower.\n",
    "\n",
    "## What You'll Learn\n",
    "1. Why blindly using `n_jobs=-1` can hurt performance\n",
    "2. How Amorsize analyzes and optimizes your workloads\n",
    "3. Hands-on examples with real performance comparisons\n",
    "4. Interactive parameter tuning playground\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install git+https://github.com/CampbellTrevor/Amorsize.git\n",
    "pip install matplotlib  # For visualizations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: The Problem with Blind Parallelization\n",
    "\n",
    "Let's see what happens when we blindly parallelize without optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "def cpu_intensive_function(x):\n",
    "    \"\"\"A CPU-intensive function that takes ~1ms per item\"\"\"\n",
    "    result = 0\n",
    "    for i in range(10000):\n",
    "        result += x ** 2\n",
    "    return result\n",
    "\n",
    "# Test data\n",
    "data = list(range(100))\n",
    "\n",
    "# Serial execution (baseline)\n",
    "start = time.time()\n",
    "serial_results = [cpu_intensive_function(x) for x in data]\n",
    "serial_time = time.time() - start\n",
    "\n",
    "print(f\"Serial execution time: {serial_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blind parallelization (might be slower!)\n",
    "start = time.time()\n",
    "with Pool(processes=os.cpu_count()) as pool:\n",
    "    parallel_results = pool.map(cpu_intensive_function, data, chunksize=1)\n",
    "blind_parallel_time = time.time() - start\n",
    "\n",
    "print(f\"Blind parallel time: {blind_parallel_time:.3f}s\")\n",
    "print(f\"Speedup: {serial_time / blind_parallel_time:.2f}x\")\n",
    "\n",
    "if blind_parallel_time > serial_time:\n",
    "    print(\"\u26a0\ufe0f NEGATIVE SCALING! Parallelism made it SLOWER!\")\n",
    "else:\n",
    "    print(\"\u2705 Got some speedup, but is it optimal?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why does this happen?**\n",
    "\n",
    "- Process spawning overhead (especially on Windows/macOS)\n",
    "- Data serialization (pickle) overhead\n",
    "- Inter-process communication overhead\n",
    "- Small chunksize = more overhead\n",
    "- Too many workers = cache thrashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: The Amorsize Solution\n",
    "\n",
    "Now let's use Amorsize to automatically find optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amorsize import optimize\n",
    "\n",
    "# Analyze and get optimal parameters\n",
    "result = optimize(\n",
    "    func=cpu_intensive_function,\n",
    "    data=data,\n",
    "    verbose=True,\n",
    "    sample_size=10  # Quick analysis with 10 samples\n",
    ")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Optimization Results:\")\n",
    "print(f\"   Recommended n_jobs: {result.n_jobs}\")\n",
    "print(f\"   Recommended chunksize: {result.chunksize}\")\n",
    "print(f\"   Estimated speedup: {result.estimated_speedup:.2f}x\")\n",
    "print(f\"   Parallel beneficial: {result.n_jobs > 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did Amorsize analyze?\n",
    "\n",
    "Amorsize performed a comprehensive analysis:\n",
    "- \u2705 Measured function execution time with dry runs\n",
    "- \u2705 Detected physical CPU cores (not hyperthreaded)\n",
    "- \u2705 Measured OS overhead (fork vs spawn)\n",
    "- \u2705 Calculated optimal chunksize for ~200ms target duration\n",
    "- \u2705 Applied Amdahl's Law for speedup estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute with optimized parameters\n",
    "from amorsize import execute\n",
    "\n",
    "start = time.time()\n",
    "optimized_results = execute(cpu_intensive_function, data, verbose=False)\n",
    "optimized_time = time.time() - start\n",
    "\n",
    "print(f\"\\n\u26a1 Performance Comparison:\")\n",
    "print(f\"   Serial time:         {serial_time:.3f}s\")\n",
    "print(f\"   Blind parallel:      {blind_parallel_time:.3f}s ({serial_time/blind_parallel_time:.2f}x)\")\n",
    "print(f\"   Amorsize optimized:  {optimized_time:.3f}s ({serial_time/optimized_time:.2f}x)\")\n",
    "print(f\"\\n\ud83c\udfaf Improvement: {blind_parallel_time/optimized_time:.2f}x better than blind parallelization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Visualizing the Optimization\n",
    "\n",
    "Let's visualize how different configurations perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Performance comparison bar chart\n",
    "configs = ['Serial', 'Blind\\nParallel', 'Amorsize\\nOptimized']\n",
    "times = [serial_time, blind_parallel_time, optimized_time]\n",
    "speedups = [1.0, serial_time/blind_parallel_time, serial_time/optimized_time]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Execution time comparison\n",
    "bars1 = ax1.bar(configs, times, color=['gray', 'orange', 'green'])\n",
    "ax1.set_ylabel('Execution Time (seconds)', fontsize=12)\n",
    "ax1.set_title('Execution Time Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, time_val in zip(bars1, times):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{time_val:.3f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Speedup comparison\n",
    "bars2 = ax2.bar(configs, speedups, color=['gray', 'orange', 'green'])\n",
    "ax2.set_ylabel('Speedup vs Serial', fontsize=12)\n",
    "ax2.set_title('Speedup Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.axhline(y=1.0, color='r', linestyle='--', label='Serial baseline')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, speedup in zip(bars2, speedups):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{speedup:.2f}x', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Key Insight: Amorsize optimized configuration is {blind_parallel_time/optimized_time:.2f}x faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Diagnostic Insights\n",
    "\n",
    "Amorsize provides detailed diagnostic information about why it made its recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed diagnostic profile\n",
    "result = optimize(\n",
    "    func=cpu_intensive_function,\n",
    "    data=data,\n",
    "    verbose=False,\n",
    "    profile=True  # Enable detailed profiling\n",
    ")\n",
    "\n",
    "profile = result.profile\n",
    "\n",
    "print(\"\ud83d\udd0d Diagnostic Profile:\")\n",
    "print(f\"\\n\ud83d\udce6 Workload Characteristics:\")\n",
    "print(f\"   Total items:              {profile.total_items}\")\n",
    "print(f\"   Avg execution time:       {profile.avg_execution_time*1000:.2f}ms per item\")\n",
    "print(f\"   Workload type:            {profile.workload_type}\")\n",
    "print(f\"   Coefficient of variation: {profile.coefficient_of_variation:.3f}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udda5\ufe0f  System Information:\")\n",
    "print(f\"   Physical cores:           {profile.physical_cores}\")\n",
    "print(f\"   Logical cores:            {profile.logical_cores}\")\n",
    "print(f\"   Start method:             {profile.multiprocessing_start_method}\")\n",
    "print(f\"   Spawn cost:               {profile.spawn_cost*1000:.1f}ms per worker\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Optimization Decisions:\")\n",
    "print(f\"   Max workers (CPU):        {profile.max_workers_cpu}\")\n",
    "print(f\"   Max workers (Memory):     {profile.max_workers_memory}\")\n",
    "print(f\"   Optimal chunksize:        {profile.optimal_chunksize}\")\n",
    "print(f\"   Target chunk duration:    {profile.target_chunk_duration*1000:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Interactive Parameter Exploration\n",
    "\n",
    "Let's explore how different worker counts affect performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different worker counts\n",
    "worker_counts = [1, 2, 4, 8, 16]\n",
    "execution_times = []\n",
    "speedups = []\n",
    "\n",
    "print(\"Testing different worker counts...\\n\")\n",
    "\n",
    "for n_workers in worker_counts:\n",
    "    if n_workers > os.cpu_count():\n",
    "        continue  # Skip if more than available cores\n",
    "    \n",
    "    start = time.time()\n",
    "    with Pool(processes=n_workers) as pool:\n",
    "        # Use Amorsize's recommended chunksize\n",
    "        results = pool.map(cpu_intensive_function, data, \n",
    "                          chunksize=result.chunksize)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    execution_times.append(elapsed)\n",
    "    speedup = serial_time / elapsed\n",
    "    speedups.append(speedup)\n",
    "    \n",
    "    marker = \"\u2b50\" if n_workers == result.n_jobs else \"  \"\n",
    "    print(f\"{marker} n_jobs={n_workers:2d}: {elapsed:.3f}s (speedup: {speedup:.2f}x)\")\n",
    "\n",
    "print(f\"\\n\u2b50 = Amorsize recommendation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scaling curve\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Execution time vs workers\n",
    "ax1.plot(worker_counts[:len(execution_times)], execution_times, 'o-', linewidth=2, markersize=8)\n",
    "ax1.axvline(x=result.n_jobs, color='g', linestyle='--', linewidth=2, label=f'Amorsize: {result.n_jobs} workers')\n",
    "ax1.set_xlabel('Number of Workers', fontsize=12)\n",
    "ax1.set_ylabel('Execution Time (seconds)', fontsize=12)\n",
    "ax1.set_title('Execution Time vs Worker Count', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Speedup vs workers\n",
    "ax2.plot(worker_counts[:len(speedups)], speedups, 'o-', linewidth=2, markersize=8, color='green')\n",
    "ax2.plot(worker_counts[:len(speedups)], worker_counts[:len(speedups)], '--', alpha=0.5, label='Linear speedup (ideal)')\n",
    "ax2.axvline(x=result.n_jobs, color='g', linestyle='--', linewidth=2, label=f'Amorsize: {result.n_jobs} workers')\n",
    "ax2.set_xlabel('Number of Workers', fontsize=12)\n",
    "ax2.set_ylabel('Speedup vs Serial', fontsize=12)\n",
    "ax2.set_title('Speedup vs Worker Count', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Observation: Adding more workers doesn't always help!\")\n",
    "print(f\"   Amorsize found the sweet spot at {result.n_jobs} workers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Real-World Example - Data Processing\n",
    "\n",
    "Let's apply Amorsize to a practical data processing scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def process_transaction(transaction):\n",
    "    \"\"\"Process a financial transaction with validation and calculations\"\"\"\n",
    "    user_id, amount, category = transaction\n",
    "    \n",
    "    # Simulate validation\n",
    "    if amount < 0:\n",
    "        return {'error': 'negative amount'}\n",
    "    \n",
    "    # Calculate derived values\n",
    "    tax = amount * 0.15\n",
    "    fee = amount * 0.02\n",
    "    total = amount + tax + fee\n",
    "    \n",
    "    # Simulate some computation\n",
    "    category_code = hash(category) % 1000\n",
    "    risk_score = (amount * category_code) % 100\n",
    "    \n",
    "    return {\n",
    "        'user_id': user_id,\n",
    "        'amount': amount,\n",
    "        'tax': tax,\n",
    "        'fee': fee,\n",
    "        'total': total,\n",
    "        'category_code': category_code,\n",
    "        'risk_score': risk_score\n",
    "    }\n",
    "\n",
    "# Generate sample transactions\n",
    "categories = ['food', 'transport', 'entertainment', 'utilities', 'healthcare']\n",
    "transactions = [\n",
    "    (i, random.uniform(10, 1000), random.choice(categories))\n",
    "    for i in range(5000)\n",
    "]\n",
    "\n",
    "print(f\"Generated {len(transactions)} transactions\")\n",
    "print(f\"Sample: {transactions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process with Amorsize\n",
    "from amorsize import execute\n",
    "\n",
    "start = time.time()\n",
    "processed = execute(process_transaction, transactions, verbose=True)\n",
    "amorsize_time = time.time() - start\n",
    "\n",
    "print(f\"\\n\u2705 Processed {len(processed)} transactions in {amorsize_time:.3f}s\")\n",
    "print(f\"\\nSample result:\")\n",
    "print(processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with serial execution\n",
    "start = time.time()\n",
    "serial_processed = [process_transaction(t) for t in transactions]\n",
    "serial_proc_time = time.time() - start\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Performance Comparison:\")\n",
    "print(f\"   Serial:    {serial_proc_time:.3f}s\")\n",
    "print(f\"   Amorsize:  {amorsize_time:.3f}s\")\n",
    "print(f\"   Speedup:   {serial_proc_time/amorsize_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Blind Parallelization is Risky**\n",
    "   - Using `n_jobs=-1` and `chunksize=1` can make code slower\n",
    "   - Overhead from process spawning, serialization, and communication\n",
    "\n",
    "2. **Amorsize Provides Intelligence**\n",
    "   - Analyzes function execution time and characteristics\n",
    "   - Considers system resources (CPU, memory)\n",
    "   - Calculates optimal parameters using Amdahl's Law\n",
    "\n",
    "3. **Simple API**\n",
    "   - One-line execution: `execute(func, data)`\n",
    "   - Two-step workflow: `optimize()` then `Pool.map()`\n",
    "   - Detailed diagnostics available\n",
    "\n",
    "4. **Real Performance Gains**\n",
    "   - Typical speedups: 5-8x for CPU-bound workloads\n",
    "   - Avoids negative scaling scenarios\n",
    "   - Works with various workload types\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- \ud83d\udcd6 Read [Use Case Guides](https://github.com/CampbellTrevor/Amorsize/tree/main/docs) for your domain:\n",
    "  - Web Services (Django, Flask, FastAPI)\n",
    "  - Data Processing (Pandas, CSV, databases)\n",
    "  - ML Pipelines (PyTorch, TensorFlow, feature engineering)\n",
    "\n",
    "- \ud83d\udd27 Explore advanced features:\n",
    "  - Checkpoint/Resume for long-running jobs\n",
    "  - Dead Letter Queue for handling failures\n",
    "  - Circuit Breaker for cascade failure prevention\n",
    "  - Monitoring hooks for production observability\n",
    "\n",
    "- \ud83d\udcca Try other notebooks:\n",
    "  - `02_performance_analysis.ipynb` - Deep dive into bottleneck analysis\n",
    "  - `03_parameter_tuning.ipynb` - Advanced parameter optimization\n",
    "  - `04_monitoring.ipynb` - Real-time monitoring and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix: Troubleshooting Common Issues\n",
    "\n",
    "### Issue 1: Function Not Picklable\n",
    "\n",
    "**Problem:** Lambda functions or nested functions can't be serialized\n",
    "\n",
    "```python\n",
    "# \u274c Won't work\n",
    "result = execute(lambda x: x**2, data)\n",
    "\n",
    "# \u2705 Works\n",
    "def square(x):\n",
    "    return x**2\n",
    "result = execute(square, data)\n",
    "```\n",
    "\n",
    "### Issue 2: No Speedup Benefit\n",
    "\n",
    "**Problem:** Function is too fast, parallelization overhead dominates\n",
    "\n",
    "```python\n",
    "# Amorsize will recommend n_jobs=1 (serial)\n",
    "result = optimize(lambda x: x**2, data, verbose=True)\n",
    "# Output: \"Parallelization not beneficial. Use serial execution.\"\n",
    "```\n",
    "\n",
    "### Issue 3: Memory Errors\n",
    "\n",
    "**Problem:** Large return objects cause OOM\n",
    "\n",
    "```python\n",
    "# Use batch processing\n",
    "from amorsize import process_in_batches\n",
    "\n",
    "for batch_results in process_in_batches(func, data, max_memory_mb=1000):\n",
    "    # Process batch results immediately\n",
    "    save_to_disk(batch_results)\n",
    "```\n",
    "\n",
    "### Issue 4: Windows/macOS Slower Than Expected\n",
    "\n",
    "**Problem:** `spawn` start method has higher overhead than `fork`\n",
    "\n",
    "```python\n",
    "# Amorsize automatically accounts for this\n",
    "# It measures spawn cost and adjusts recommendations\n",
    "result = optimize(func, data, verbose=True)\n",
    "# Check: result.profile.spawn_cost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83c\udf89 Congratulations!\n",
    "\n",
    "You've completed the Getting Started tutorial!\n",
    "\n",
    "You now know how to:\n",
    "- \u2705 Use Amorsize to automatically optimize multiprocessing parameters\n",
    "- \u2705 Avoid negative scaling where parallelism hurts performance\n",
    "- \u2705 Visualize and understand optimization decisions\n",
    "- \u2705 Apply Amorsize to real-world data processing scenarios\n",
    "\n",
    "Happy optimizing! \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}